{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af55417e-f5b9-45db-a9ae-6ef575bc3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this code, we want to implement paper trading using andrew's data\n",
    "# paper trading simulation is in progress (10%)\n",
    "# here we use StockTradingEnv: from finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1f6640-bf05-496d-88df-6bbe72b0d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Model's Actions (v1, 29-11-2024) during inference (we only save stocks that has been bought minimum once during inference): \n",
    "# https://docs.google.com/spreadsheets/d/1hxAylDM_5tRWs4pfmGRtkeWghsqYNH-M/edit?usp=sharing&ouid=115732800758806068195&rtpof=true&sd=true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de5849f0-025b-4922-9f1a-18a4f4a048f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this is the latest detailed actions (v2, 02-12-2024)\n",
    "# https://docs.google.com/spreadsheets/d/1dsItSiZKYXDjsDwNN3hBpRb2EGPSX1Zh/edit?usp=sharing&ouid=115732800758806068195&rtpof=true&sd=true\n",
    "# the previous one (v1) model got deleted, and cannot be replicated (different training run always yield different result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c30e4ef-8613-4f57-956f-b15414dbda14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# raw_df = pd.read_csv(\"../tuntun_data/Daily93Tuntun_2010-2021.csv\")\n",
    "# raw_df = raw_df[pd.to_datetime(raw_df['date']) > pd.Timestamp('2009-01-01')]\n",
    "# raw_df = raw_df[~raw_df['tic'].str.contains('-')]\n",
    "# raw_df = raw_df.drop_duplicates(subset=['date', 'tic'])\n",
    "# raw_df['date'] = pd.to_datetime(raw_df['date'])\n",
    "# raw_df = raw_df.sort_values('date').reset_index(drop=True)\n",
    "# date_mapping = {date: i+1 for i, date in enumerate(raw_df['date'].unique())}\n",
    "# raw_df['day'] = raw_df['date'].map(date_mapping)\n",
    "# raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e66b4b8-7ed4-4afc-89da-02c076599081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume_zero_count = raw_df[raw_df['volume'] == 0].groupby('tic').size()\n",
    "# sorted_volume_zero_count = volume_zero_count.sort_values(ascending=True)\n",
    "# top_n_tic = sorted_volume_zero_count.head(100)\n",
    "# tickers = top_n_tic.index.tolist()\n",
    "# df = raw_df[raw_df[\"tic\"].isin(tickers)]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc82e11-7206-4d11-a683-9d258f81d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = pd.to_datetime(df['date'])\n",
    "# df = df.sort_values('date').reset_index(drop=True)\n",
    "# date_mapping = {date: i+1 for i, date in enumerate(df['date'].unique())}\n",
    "# df['day'] = df['date'].map(date_mapping)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803e17b0-32f3-49e9-b74b-68f170bd0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finrl.config import INDICATORS\n",
    "# from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
    "# fe = FeatureEngineer(use_technical_indicator=True,\n",
    "#                      tech_indicator_list = INDICATORS,\n",
    "#                      use_turbulence=True,\n",
    "#                      user_defined_feature = False)\n",
    "\n",
    "# processed = fe.preprocess_data(df)\n",
    "# processed = processed.copy()\n",
    "# processed = processed.fillna(0)\n",
    "# processed = processed.replace(np.inf,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7368e2bc-661c-4e17-a309-2146a43aef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_fout = \"tuntun_data/processed_load_tuntun_data_v3.csv\"\n",
    "# processed.to_csv(processed_fout, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addcf03a-8491-4508-b114-6fc6ce7e2947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>16400</td>\n",
       "      <td>ADES</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1059.142136</td>\n",
       "      <td>1030.857864</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>10488900</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1059.142136</td>\n",
       "      <td>1030.857864</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1230.000000</td>\n",
       "      <td>1230.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>168.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1533600</td>\n",
       "      <td>AGRO</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1059.142136</td>\n",
       "      <td>1030.857864</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>50.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>491000</td>\n",
       "      <td>AHAP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1059.142136</td>\n",
       "      <td>1030.857864</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>754400</td>\n",
       "      <td>AKSI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1059.142136</td>\n",
       "      <td>1030.857864</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1365.000000</td>\n",
       "      <td>1365.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50195</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>62.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>540238000</td>\n",
       "      <td>WOWS</td>\n",
       "      <td>502</td>\n",
       "      <td>3.040278</td>\n",
       "      <td>73.845670</td>\n",
       "      <td>42.854330</td>\n",
       "      <td>54.242553</td>\n",
       "      <td>66.792453</td>\n",
       "      <td>51.675347</td>\n",
       "      <td>56.400000</td>\n",
       "      <td>53.400000</td>\n",
       "      <td>163.237228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50196</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>112.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>61218500</td>\n",
       "      <td>WSBP</td>\n",
       "      <td>502</td>\n",
       "      <td>-6.738763</td>\n",
       "      <td>129.522520</td>\n",
       "      <td>108.577480</td>\n",
       "      <td>36.126025</td>\n",
       "      <td>-85.778781</td>\n",
       "      <td>2.908290</td>\n",
       "      <td>124.466667</td>\n",
       "      <td>142.383333</td>\n",
       "      <td>163.237228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50197</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>534.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>17500</td>\n",
       "      <td>XIIT</td>\n",
       "      <td>502</td>\n",
       "      <td>-0.924054</td>\n",
       "      <td>540.884194</td>\n",
       "      <td>526.115806</td>\n",
       "      <td>50.926870</td>\n",
       "      <td>-81.896552</td>\n",
       "      <td>7.403819</td>\n",
       "      <td>534.566667</td>\n",
       "      <td>536.483333</td>\n",
       "      <td>163.237228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50198</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>118.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>583554500</td>\n",
       "      <td>YELO</td>\n",
       "      <td>502</td>\n",
       "      <td>-12.705238</td>\n",
       "      <td>171.100852</td>\n",
       "      <td>128.499148</td>\n",
       "      <td>43.502529</td>\n",
       "      <td>-134.885417</td>\n",
       "      <td>11.455186</td>\n",
       "      <td>158.566667</td>\n",
       "      <td>176.202333</td>\n",
       "      <td>163.237228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50199</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>410.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>196600</td>\n",
       "      <td>ZONE</td>\n",
       "      <td>502</td>\n",
       "      <td>1.779834</td>\n",
       "      <td>412.367577</td>\n",
       "      <td>401.832423</td>\n",
       "      <td>58.961655</td>\n",
       "      <td>192.105263</td>\n",
       "      <td>18.151774</td>\n",
       "      <td>405.066667</td>\n",
       "      <td>405.166667</td>\n",
       "      <td>163.237228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50200 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    open    high     low   close     volume   tic  day  \\\n",
       "0      2019-12-10  1025.0  1045.0  1025.0  1040.0      16400  ADES    1   \n",
       "1      2019-12-10  1265.0  1275.0  1215.0  1230.0   10488900  ADHI    1   \n",
       "2      2019-12-10   168.0   174.0   168.0   169.0    1533600  AGRO    1   \n",
       "3      2019-12-10    50.0    59.0    50.0    58.0     491000  AHAP    1   \n",
       "4      2019-12-10  1390.0  1415.0  1360.0  1365.0     754400  AKSI    1   \n",
       "...           ...     ...     ...     ...     ...        ...   ...  ...   \n",
       "50195  2021-12-30    62.0    69.0    58.0    60.0  540238000  WOWS  502   \n",
       "50196  2021-12-30   112.0   121.0   110.0   114.0   61218500  WSBP  502   \n",
       "50197  2021-12-30   534.0   534.0   530.0   530.0      17500  XIIT  502   \n",
       "50198  2021-12-30   118.0   153.0   118.0   135.0  583554500  YELO  502   \n",
       "50199  2021-12-30   410.0   414.0   410.0   414.0     196600  ZONE  502   \n",
       "\n",
       "            macd      boll_ub      boll_lb      rsi_30      cci_30  \\\n",
       "0       0.000000  1059.142136  1030.857864  100.000000   66.666667   \n",
       "1       0.000000  1059.142136  1030.857864  100.000000   66.666667   \n",
       "2       0.000000  1059.142136  1030.857864  100.000000   66.666667   \n",
       "3       0.000000  1059.142136  1030.857864  100.000000   66.666667   \n",
       "4       0.000000  1059.142136  1030.857864  100.000000   66.666667   \n",
       "...          ...          ...          ...         ...         ...   \n",
       "50195   3.040278    73.845670    42.854330   54.242553   66.792453   \n",
       "50196  -6.738763   129.522520   108.577480   36.126025  -85.778781   \n",
       "50197  -0.924054   540.884194   526.115806   50.926870  -81.896552   \n",
       "50198 -12.705238   171.100852   128.499148   43.502529 -134.885417   \n",
       "50199   1.779834   412.367577   401.832423   58.961655  192.105263   \n",
       "\n",
       "            dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0      100.000000   1040.000000   1040.000000    0.000000  \n",
       "1      100.000000   1230.000000   1230.000000    0.000000  \n",
       "2      100.000000    169.000000    169.000000    0.000000  \n",
       "3      100.000000     58.000000     58.000000    0.000000  \n",
       "4      100.000000   1365.000000   1365.000000    0.000000  \n",
       "...           ...           ...           ...         ...  \n",
       "50195   51.675347     56.400000     53.400000  163.237228  \n",
       "50196    2.908290    124.466667    142.383333  163.237228  \n",
       "50197    7.403819    534.566667    536.483333  163.237228  \n",
       "50198   11.455186    158.566667    176.202333  163.237228  \n",
       "50199   18.151774    405.066667    405.166667  163.237228  \n",
       "\n",
       "[50200 rows x 17 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "processed_fout = \"tuntun_data/processed_load_tuntun_data_v3.csv\"\n",
    "processed = pd.read_csv(processed_fout)\n",
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f860b8e9-74aa-4f29-979e-5edd10d4c9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = processed[\"tic\"].unique()\n",
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1738ebe5-154c-422b-b1f4-820b898fc0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6d7386-ba01-4a3e-9e5a-7019a05e090f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finrl.config import INDICATORS\n",
    "INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac566f2-fbfd-4fc1-892d-391bb03bdd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StockTradingEnv\n",
    "drl_lib = \"elegantrl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e42d28d-9089-407f-afe0-4da3ea5c100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed = processed[processed[\"day\"] < 442]\n",
    "test_processed = processed[processed[\"day\"] >= 442]\n",
    "price_array, tech_array, turbulence_array, train_tickers, train_dates = df_to_array(train_processed, INDICATORS)\n",
    "\n",
    "env_config = {\n",
    "    \"price_array\": price_array,\n",
    "    \"tech_array\": tech_array,\n",
    "    \"turbulence_array\": turbulence_array,\n",
    "    \"if_train\": True,\n",
    "}\n",
    "env_instance = env(config=env_config)\n",
    "ERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n",
    "        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,\n",
    "        \"eval_times\":1}\n",
    "\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = \"ppo\"\n",
    "cwd = f\"tuntun_papertrading_erl/{model_name}_{timestamp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43407b52-bf2c-4b41-b5db-7e8fe04cc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if drl_lib == \"elegantrl\":\n",
    "#     DRLAgent_erl = DRLAgent\n",
    "#     break_step = 1e5\n",
    "#     agent = DRLAgent(\n",
    "#         env=env,\n",
    "#         price_array=price_array,\n",
    "#         tech_array=tech_array,\n",
    "#         turbulence_array=turbulence_array,\n",
    "#     )\n",
    "#     model = agent.get_model(model_name, model_kwargs=ERL_PARAMS)\n",
    "#     trained_model = agent.train_model(\n",
    "#         model=model, cwd=cwd, total_timesteps=break_step\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b240b68a-9b22-4a19-950f-85b843cba258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 3e-06,\n",
       " 'batch_size': 2048,\n",
       " 'gamma': 0.985,\n",
       " 'seed': 312,\n",
       " 'net_dimension': [128, 64],\n",
       " 'target_step': 5000,\n",
       " 'eval_gap': 30,\n",
       " 'eval_times': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERL_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61ddfadf-5e6e-4d74-a3cd-ae82b5718e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total all days in dataset 502\n",
      "total all days in train data 441\n",
      "total all days in test data 61\n"
     ]
    }
   ],
   "source": [
    "days = processed[\"day\"].unique()\n",
    "print(f\"total all days in dataset {len(days)}\")\n",
    "days = train_processed[\"day\"].unique()\n",
    "print(f\"total all days in train data {len(days)}\")\n",
    "days = test_processed[\"day\"].unique()\n",
    "print(f\"total all days in test data {len(days)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb779dc6-3144-4959-8fe2-2cb83e0dc6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44101</th>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>46008000</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>442</td>\n",
       "      <td>77.787721</td>\n",
       "      <td>1107.297099</td>\n",
       "      <td>738.202901</td>\n",
       "      <td>69.537289</td>\n",
       "      <td>188.528807</td>\n",
       "      <td>69.912065</td>\n",
       "      <td>867.333333</td>\n",
       "      <td>785.750000</td>\n",
       "      <td>173.352789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44201</th>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>36252100</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>443</td>\n",
       "      <td>80.295447</td>\n",
       "      <td>1129.193430</td>\n",
       "      <td>744.306570</td>\n",
       "      <td>68.441694</td>\n",
       "      <td>168.045222</td>\n",
       "      <td>67.250570</td>\n",
       "      <td>880.166667</td>\n",
       "      <td>792.166667</td>\n",
       "      <td>135.549417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44301</th>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>26977000</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>444</td>\n",
       "      <td>81.744002</td>\n",
       "      <td>1148.108210</td>\n",
       "      <td>753.391790</td>\n",
       "      <td>68.696796</td>\n",
       "      <td>149.000921</td>\n",
       "      <td>67.250570</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>71.242759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44401</th>\n",
       "      <td>2021-10-11</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>28772800</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>445</td>\n",
       "      <td>81.149634</td>\n",
       "      <td>1160.349029</td>\n",
       "      <td>768.650971</td>\n",
       "      <td>67.566773</td>\n",
       "      <td>130.394215</td>\n",
       "      <td>64.309593</td>\n",
       "      <td>905.000000</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>111.762992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44501</th>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>76551700</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>446</td>\n",
       "      <td>83.747782</td>\n",
       "      <td>1180.576581</td>\n",
       "      <td>778.923419</td>\n",
       "      <td>70.109918</td>\n",
       "      <td>142.322938</td>\n",
       "      <td>71.318275</td>\n",
       "      <td>918.500000</td>\n",
       "      <td>814.000000</td>\n",
       "      <td>104.749180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49701</th>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>885.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>10191100</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>498</td>\n",
       "      <td>-46.321131</td>\n",
       "      <td>1139.931883</td>\n",
       "      <td>878.068117</td>\n",
       "      <td>39.924749</td>\n",
       "      <td>-174.664107</td>\n",
       "      <td>42.614869</td>\n",
       "      <td>1045.500000</td>\n",
       "      <td>1076.500000</td>\n",
       "      <td>103.553118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49801</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>905.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>18381100</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>499</td>\n",
       "      <td>-43.206738</td>\n",
       "      <td>1132.061368</td>\n",
       "      <td>874.438632</td>\n",
       "      <td>45.466862</td>\n",
       "      <td>-112.825577</td>\n",
       "      <td>20.224608</td>\n",
       "      <td>1041.166667</td>\n",
       "      <td>1074.833333</td>\n",
       "      <td>106.628102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49901</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>965.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>27526200</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>500</td>\n",
       "      <td>-43.465185</td>\n",
       "      <td>1131.550700</td>\n",
       "      <td>864.449300</td>\n",
       "      <td>42.747173</td>\n",
       "      <td>-110.382644</td>\n",
       "      <td>14.461727</td>\n",
       "      <td>1035.333333</td>\n",
       "      <td>1071.916667</td>\n",
       "      <td>113.662820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>920.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>15705100</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>501</td>\n",
       "      <td>-43.970063</td>\n",
       "      <td>1131.196943</td>\n",
       "      <td>853.803057</td>\n",
       "      <td>42.095953</td>\n",
       "      <td>-128.482972</td>\n",
       "      <td>19.931984</td>\n",
       "      <td>1028.666667</td>\n",
       "      <td>1069.166667</td>\n",
       "      <td>123.081425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50101</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>910.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>6074400</td>\n",
       "      <td>ADHI</td>\n",
       "      <td>502</td>\n",
       "      <td>-45.061121</td>\n",
       "      <td>1129.799516</td>\n",
       "      <td>841.700484</td>\n",
       "      <td>41.123814</td>\n",
       "      <td>-119.439868</td>\n",
       "      <td>19.931984</td>\n",
       "      <td>1021.333333</td>\n",
       "      <td>1065.666667</td>\n",
       "      <td>163.237228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    open    high     low   close    volume   tic  day  \\\n",
       "44101  2021-10-06  1090.0  1140.0  1085.0  1105.0  46008000  ADHI  442   \n",
       "44201  2021-10-07  1105.0  1135.0  1080.0  1095.0  36252100  ADHI  443   \n",
       "44301  2021-10-08  1100.0  1115.0  1080.0  1100.0  26977000  ADHI  444   \n",
       "44401  2021-10-11  1100.0  1105.0  1075.0  1090.0  28772800  ADHI  445   \n",
       "44501  2021-10-12  1090.0  1170.0  1075.0  1140.0  76551700  ADHI  446   \n",
       "...           ...     ...     ...     ...     ...       ...   ...  ...   \n",
       "49701  2021-12-24   885.0   910.0   880.0   900.0  10191100  ADHI  498   \n",
       "49801  2021-12-27   905.0   960.0   905.0   960.0  18381100  ADHI  499   \n",
       "49901  2021-12-28   965.0   975.0   910.0   920.0  27526200  ADHI  500   \n",
       "50001  2021-12-29   920.0   920.0   890.0   910.0  15705100  ADHI  501   \n",
       "50101  2021-12-30   910.0   920.0   895.0   895.0   6074400  ADHI  502   \n",
       "\n",
       "            macd      boll_ub     boll_lb     rsi_30      cci_30      dx_30  \\\n",
       "44101  77.787721  1107.297099  738.202901  69.537289  188.528807  69.912065   \n",
       "44201  80.295447  1129.193430  744.306570  68.441694  168.045222  67.250570   \n",
       "44301  81.744002  1148.108210  753.391790  68.696796  149.000921  67.250570   \n",
       "44401  81.149634  1160.349029  768.650971  67.566773  130.394215  64.309593   \n",
       "44501  83.747782  1180.576581  778.923419  70.109918  142.322938  71.318275   \n",
       "...          ...          ...         ...        ...         ...        ...   \n",
       "49701 -46.321131  1139.931883  878.068117  39.924749 -174.664107  42.614869   \n",
       "49801 -43.206738  1132.061368  874.438632  45.466862 -112.825577  20.224608   \n",
       "49901 -43.465185  1131.550700  864.449300  42.747173 -110.382644  14.461727   \n",
       "50001 -43.970063  1131.196943  853.803057  42.095953 -128.482972  19.931984   \n",
       "50101 -45.061121  1129.799516  841.700484  41.123814 -119.439868  19.931984   \n",
       "\n",
       "       close_30_sma  close_60_sma  turbulence  \n",
       "44101    867.333333    785.750000  173.352789  \n",
       "44201    880.166667    792.166667  135.549417  \n",
       "44301    893.000000    799.000000   71.242759  \n",
       "44401    905.000000    806.000000  111.762992  \n",
       "44501    918.500000    814.000000  104.749180  \n",
       "...             ...           ...         ...  \n",
       "49701   1045.500000   1076.500000  103.553118  \n",
       "49801   1041.166667   1074.833333  106.628102  \n",
       "49901   1035.333333   1071.916667  113.662820  \n",
       "50001   1028.666667   1069.166667  123.081425  \n",
       "50101   1021.333333   1065.666667  163.237228  \n",
       "\n",
       "[61 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adhi = test_processed[test_processed[\"tic\"] == \"ADHI\"]\n",
    "adhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ce41f8e-366a-4262-be0e-621097b45302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tuntun_papertrading_erl/ppo_20241204_125840'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = \"tuntun_papertrading_erl/ppo_20241204_125840\"\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6044818-da29-4ebc-a40f-f1ddae86f909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_array: 61 days\n",
      "| load actor from: tuntun_papertrading_erl/ppo_20241204_125840/actor.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1321556/3437315404.py:91: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  actor.load_state_dict(torch.load(cwd, map_location=lambda storage, loc: storage))\n",
      "/tmp/ipykernel_1321556/3437315404.py:104: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  s_tensor = _torch.as_tensor((state,), device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Finished!\n",
      "episode_return 1.1270492354734734\n",
      "EPISODE TOTAL ASSETS: [1000000.0, 1000000.0, 999001.0300000001, 958821.2800000001, 958821.2800000001, 958821.2800000001, 958821.2800000001, 957863.4112992366, 978179.4474242366, 978179.4474242366, 978179.4474242366, 978179.4474242366, 978179.4474242366, 978179.4474242366, 977202.2674242365, 976212.2674242365, 1015700.5724242366, 1015700.5724242366, 1015700.5724242366, 1015700.5724242366, 1015700.5724242366, 1014685.882723473, 1063783.605473473, 1063783.605473473, 1063783.605473473, 1063783.605473473, 1063783.605473473, 1063783.605473473, 1063783.605473473, 1063783.605473473, 1063783.605473473, 1062720.9204734731, 1063096.7954734731, 1062034.7954734731, 1092406.330473473, 1092406.330473473, 1092406.330473473, 1092406.330473473, 1092406.330473473, 1092406.330473473, 1092406.330473473, 1092406.330473473, 1092406.330473473, 1092406.330473473, 1092406.330473473, 1092406.330473473, 1091315.020473473, 1081317.625473473, 1080237.4004734734, 1096562.4004734734, 1127049.2354734733, 1127049.2354734733, 1127049.2354734733, 1127049.2354734733, 1127049.2354734733, 1127049.2354734733, 1127049.2354734733, 1127049.2354734733, 1127049.2354734733, 1127049.2354734733, 1127049.2354734733]\n"
     ]
    }
   ],
   "source": [
    "test_price_array, test_tech_array, test_turbulence_array, test_tickers, test_dates = df_to_array(test_processed, INDICATORS)\n",
    "env_config = {\n",
    "    \"price_array\": test_price_array,\n",
    "    \"tech_array\": test_tech_array,\n",
    "    \"turbulence_array\": test_turbulence_array,\n",
    "    \"if_train\": False,\n",
    "}\n",
    "env_instance = env(config=env_config)\n",
    "\n",
    "# load elegantrl needs state dim, action dim and net dim\n",
    "net_dimension = ERL_PARAMS.get(\"net_dimension\", 2**7)\n",
    "print(f\"price_array: {len(test_price_array)} days\")\n",
    "\n",
    "if drl_lib == \"elegantrl\":\n",
    "    DRLAgent_erl = DRLAgent\n",
    "    episode_total_assets = DRLAgent_erl.DRL_prediction(\n",
    "        model_name=model_name,\n",
    "        cwd=cwd,\n",
    "        net_dimension=net_dimension,\n",
    "        environment=env_instance,\n",
    "    )\n",
    "    print(f\"EPISODE TOTAL ASSETS: {episode_total_assets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f95423d-69a7-451a-a820-2491ef8a169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed actions is saved to\n",
      "/mnt/c/Users/mahfu/Downloads/tuntun/tuntun_ubuntu/github_me/finrl/from_finrl-tutorials_git/papertrading_erl/detailed_actions_local.xlsx\n",
      "Number of tickers with at least one buy action: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>sell_all</th>\n",
       "      <th>ADHI</th>\n",
       "      <th>APIC</th>\n",
       "      <th>ARTO</th>\n",
       "      <th>ASGR</th>\n",
       "      <th>BAPI</th>\n",
       "      <th>TMAS</th>\n",
       "      <th>funds_on_market_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>1</td>\n",
       "      <td>135.549417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1095, 53, 0)</td>\n",
       "      <td>(870, 91, 0)</td>\n",
       "      <td>(13125, 81, 0)</td>\n",
       "      <td>(760, 61, 0)</td>\n",
       "      <td>(50, 19, 0)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>2</td>\n",
       "      <td>71.242759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1100, 52, 52)</td>\n",
       "      <td>(880, 90, 90)</td>\n",
       "      <td>(12925, 83, 66)</td>\n",
       "      <td>(760, 65, 12)</td>\n",
       "      <td>(50, 16, 8)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-11</td>\n",
       "      <td>3</td>\n",
       "      <td>111.762992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1090, 93, 0)</td>\n",
       "      <td>(875, 89, 0)</td>\n",
       "      <td>(12350, 63, 0)</td>\n",
       "      <td>(735, 25, 0)</td>\n",
       "      <td>(50, 35, 0)</td>\n",
       "      <td>(30, 97, 0)</td>\n",
       "      <td>958821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>4</td>\n",
       "      <td>104.749180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1140, 49, 0)</td>\n",
       "      <td>(885, 89, 0)</td>\n",
       "      <td>(12700, 82, 0)</td>\n",
       "      <td>(740, 61, 0)</td>\n",
       "      <td>(50, 14, 0)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>958821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>5</td>\n",
       "      <td>108.012925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1150, 47, 0)</td>\n",
       "      <td>(900, 90, 0)</td>\n",
       "      <td>(12250, 81, 0)</td>\n",
       "      <td>(740, 61, 0)</td>\n",
       "      <td>(50, 13, 0)</td>\n",
       "      <td>(30, 98, 0)</td>\n",
       "      <td>958821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-10-14</td>\n",
       "      <td>6</td>\n",
       "      <td>99.055134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1180, 42, 0)</td>\n",
       "      <td>(900, 89, 0)</td>\n",
       "      <td>(12375, 82, 0)</td>\n",
       "      <td>(730, 63, 0)</td>\n",
       "      <td>(50, 10, 0)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>958821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>7</td>\n",
       "      <td>73.197749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1185, 40, 40)</td>\n",
       "      <td>(910, 89, 89)</td>\n",
       "      <td>(13125, 80, 63)</td>\n",
       "      <td>(720, 63, 3)</td>\n",
       "      <td>(50, 14, 8)</td>\n",
       "      <td>(31, 98, 1)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>8</td>\n",
       "      <td>108.583841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1190, 91, 0)</td>\n",
       "      <td>(935, 88, 0)</td>\n",
       "      <td>(13425, 64, 0)</td>\n",
       "      <td>(710, 23, 0)</td>\n",
       "      <td>(50, 34, 0)</td>\n",
       "      <td>(31, 97, 0)</td>\n",
       "      <td>978179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-10-19</td>\n",
       "      <td>9</td>\n",
       "      <td>190.356449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1190, 45, 0)</td>\n",
       "      <td>(950, 90, 0)</td>\n",
       "      <td>(13825, 76, 0)</td>\n",
       "      <td>(710, 62, 0)</td>\n",
       "      <td>(50, 23, 0)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>978179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>10</td>\n",
       "      <td>256.420879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1110, 48, 0)</td>\n",
       "      <td>(945, 90, 0)</td>\n",
       "      <td>(14750, 75, 0)</td>\n",
       "      <td>(705, 62, 0)</td>\n",
       "      <td>(50, 28, 0)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>978179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>11</td>\n",
       "      <td>113.164301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1155, 53, 0)</td>\n",
       "      <td>(950, 91, 0)</td>\n",
       "      <td>(14900, 73, 0)</td>\n",
       "      <td>(710, 60, 0)</td>\n",
       "      <td>(50, 45, 0)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>978179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>12</td>\n",
       "      <td>106.783181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1125, 51, 0)</td>\n",
       "      <td>(950, 90, 0)</td>\n",
       "      <td>(14925, 73, 0)</td>\n",
       "      <td>(720, 61, 0)</td>\n",
       "      <td>(50, 45, 0)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>978179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>13</td>\n",
       "      <td>148.030183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1095, 47, 0)</td>\n",
       "      <td>(965, 90, 0)</td>\n",
       "      <td>(15175, 72, 0)</td>\n",
       "      <td>(725, 62, 0)</td>\n",
       "      <td>(50, 41, 0)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>978179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>14</td>\n",
       "      <td>85.271105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1040, 48, 48)</td>\n",
       "      <td>(955, 91, 91)</td>\n",
       "      <td>(14825, 70, 56)</td>\n",
       "      <td>(735, 63, 13)</td>\n",
       "      <td>(50, 42, 12)</td>\n",
       "      <td>(32, 98, 0)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>15</td>\n",
       "      <td>70.932055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1020, 91, 48)</td>\n",
       "      <td>(940, 85, 91)</td>\n",
       "      <td>(14850, 65, 56)</td>\n",
       "      <td>(730, 21, 13)</td>\n",
       "      <td>(50, 47, 12)</td>\n",
       "      <td>(31, 96, 0)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>16</td>\n",
       "      <td>236.089529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1050, 90, 0)</td>\n",
       "      <td>(970, 83, 0)</td>\n",
       "      <td>(15500, 67, 0)</td>\n",
       "      <td>(725, 23, 0)</td>\n",
       "      <td>(50, 51, 0)</td>\n",
       "      <td>(31, 96, 0)</td>\n",
       "      <td>1015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>17</td>\n",
       "      <td>134.478367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1060, 42, 0)</td>\n",
       "      <td>(975, 91, 0)</td>\n",
       "      <td>(15000, 72, 0)</td>\n",
       "      <td>(725, 66, 0)</td>\n",
       "      <td>(50, 50, 0)</td>\n",
       "      <td>(32, 98, 0)</td>\n",
       "      <td>1015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>18</td>\n",
       "      <td>148.687444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1040, 42, 0)</td>\n",
       "      <td>(980, 89, 0)</td>\n",
       "      <td>(15300, 75, 0)</td>\n",
       "      <td>(735, 65, 0)</td>\n",
       "      <td>(50, 50, 0)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>1015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>19</td>\n",
       "      <td>117.879127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1100, 42, 0)</td>\n",
       "      <td>(980, 91, 0)</td>\n",
       "      <td>(15400, 73, 0)</td>\n",
       "      <td>(740, 70, 0)</td>\n",
       "      <td>(50, 47, 0)</td>\n",
       "      <td>(31, 98, 0)</td>\n",
       "      <td>1015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>20</td>\n",
       "      <td>118.487992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1110, 47, 0)</td>\n",
       "      <td>(980, 91, 0)</td>\n",
       "      <td>(15200, 72, 0)</td>\n",
       "      <td>(740, 64, 0)</td>\n",
       "      <td>(50, 49, 0)</td>\n",
       "      <td>(39, 98, 0)</td>\n",
       "      <td>1015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>21</td>\n",
       "      <td>85.063194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1085, 46, 46)</td>\n",
       "      <td>(995, 91, 91)</td>\n",
       "      <td>(15175, 71, 57)</td>\n",
       "      <td>(755, 65, 12)</td>\n",
       "      <td>(50, 47, 3)</td>\n",
       "      <td>(37, 98, 1)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>22</td>\n",
       "      <td>125.648380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1080, 91, 0)</td>\n",
       "      <td>(1015, 84, 0)</td>\n",
       "      <td>(16025, 70, 0)</td>\n",
       "      <td>(765, 28, 0)</td>\n",
       "      <td>(50, 52, 0)</td>\n",
       "      <td>(39, 96, 0)</td>\n",
       "      <td>1063783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>23</td>\n",
       "      <td>168.597997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1120, 44, 0)</td>\n",
       "      <td>(1030, 92, 0)</td>\n",
       "      <td>(16725, 70, 0)</td>\n",
       "      <td>(775, 68, 0)</td>\n",
       "      <td>(50, 51, 0)</td>\n",
       "      <td>(49, 97, 0)</td>\n",
       "      <td>1063783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>24</td>\n",
       "      <td>136.224511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1140, 41, 0)</td>\n",
       "      <td>(1040, 93, 0)</td>\n",
       "      <td>(16425, 70, 0)</td>\n",
       "      <td>(770, 68, 0)</td>\n",
       "      <td>(50, 52, 0)</td>\n",
       "      <td>(48, 98, 0)</td>\n",
       "      <td>1063783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>25</td>\n",
       "      <td>183.822521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1130, 41, 0)</td>\n",
       "      <td>(1030, 93, 0)</td>\n",
       "      <td>(16275, 71, 0)</td>\n",
       "      <td>(775, 67, 0)</td>\n",
       "      <td>(50, 54, 0)</td>\n",
       "      <td>(60, 98, 0)</td>\n",
       "      <td>1063783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>26</td>\n",
       "      <td>180.512011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1110, 43, 0)</td>\n",
       "      <td>(1025, 93, 0)</td>\n",
       "      <td>(15500, 69, 0)</td>\n",
       "      <td>(765, 64, 0)</td>\n",
       "      <td>(50, 56, 0)</td>\n",
       "      <td>(61, 98, 0)</td>\n",
       "      <td>1063783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>27</td>\n",
       "      <td>107.574976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1090, 42, 0)</td>\n",
       "      <td>(1020, 92, 0)</td>\n",
       "      <td>(15625, 72, 0)</td>\n",
       "      <td>(775, 64, 0)</td>\n",
       "      <td>(50, 54, 0)</td>\n",
       "      <td>(60, 97, 0)</td>\n",
       "      <td>1063783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-11-16</td>\n",
       "      <td>28</td>\n",
       "      <td>149.493047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1095, 46, 0)</td>\n",
       "      <td>(1030, 93, 0)</td>\n",
       "      <td>(15825, 69, 0)</td>\n",
       "      <td>(780, 63, 0)</td>\n",
       "      <td>(50, 53, 0)</td>\n",
       "      <td>(62, 97, 0)</td>\n",
       "      <td>1063783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-11-17</td>\n",
       "      <td>29</td>\n",
       "      <td>193.747153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1110, 48, 0)</td>\n",
       "      <td>(1015, 93, 0)</td>\n",
       "      <td>(15800, 68, 0)</td>\n",
       "      <td>(790, 61, 0)</td>\n",
       "      <td>(50, 55, 0)</td>\n",
       "      <td>(63, 97, 0)</td>\n",
       "      <td>1063783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-11-18</td>\n",
       "      <td>30</td>\n",
       "      <td>202.796573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1115, 50, 0)</td>\n",
       "      <td>(1010, 93, 0)</td>\n",
       "      <td>(15450, 69, 0)</td>\n",
       "      <td>(785, 58, 0)</td>\n",
       "      <td>(50, 57, 0)</td>\n",
       "      <td>(64, 97, 0)</td>\n",
       "      <td>1063783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-11-19</td>\n",
       "      <td>31</td>\n",
       "      <td>87.849023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1115, 52, 52)</td>\n",
       "      <td>(1015, 93, 93)</td>\n",
       "      <td>(15500, 71, 58)</td>\n",
       "      <td>(790, 57, 14)</td>\n",
       "      <td>(50, 52, 5)</td>\n",
       "      <td>(76, 97, 0)</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-11-22</td>\n",
       "      <td>32</td>\n",
       "      <td>182.972408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1140, 90, 0)</td>\n",
       "      <td>(1015, 83, 0)</td>\n",
       "      <td>(15500, 73, 0)</td>\n",
       "      <td>(800, 23, 0)</td>\n",
       "      <td>(50, 41, 0)</td>\n",
       "      <td>(71, 96, 0)</td>\n",
       "      <td>1063096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>33</td>\n",
       "      <td>86.750593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1135, 51, 51)</td>\n",
       "      <td>(1005, 93, 93)</td>\n",
       "      <td>(14700, 70, 62)</td>\n",
       "      <td>(800, 58, -1)</td>\n",
       "      <td>(50, 49, 1)</td>\n",
       "      <td>(66, 97, 0)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>34</td>\n",
       "      <td>104.754051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1135, 91, 0)</td>\n",
       "      <td>(1010, 82, 0)</td>\n",
       "      <td>(15200, 74, 0)</td>\n",
       "      <td>(800, 27, 0)</td>\n",
       "      <td>(50, 46, 0)</td>\n",
       "      <td>(67, 96, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-11-25</td>\n",
       "      <td>35</td>\n",
       "      <td>134.225604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1155, 53, 0)</td>\n",
       "      <td>(1045, 93, 0)</td>\n",
       "      <td>(15200, 73, 0)</td>\n",
       "      <td>(805, 62, 0)</td>\n",
       "      <td>(50, 50, 0)</td>\n",
       "      <td>(73, 98, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2021-11-26</td>\n",
       "      <td>36</td>\n",
       "      <td>119.054191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1095, 54, 0)</td>\n",
       "      <td>(1040, 93, 0)</td>\n",
       "      <td>(14750, 74, 0)</td>\n",
       "      <td>(795, 66, 0)</td>\n",
       "      <td>(50, 45, 0)</td>\n",
       "      <td>(70, 97, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2021-11-29</td>\n",
       "      <td>37</td>\n",
       "      <td>123.803598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1075, 54, 0)</td>\n",
       "      <td>(1050, 92, 0)</td>\n",
       "      <td>(15375, 76, 0)</td>\n",
       "      <td>(780, 66, 0)</td>\n",
       "      <td>(50, 47, 0)</td>\n",
       "      <td>(80, 98, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>38</td>\n",
       "      <td>159.324943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1025, 55, 0)</td>\n",
       "      <td>(1090, 92, 0)</td>\n",
       "      <td>(15825, 77, 0)</td>\n",
       "      <td>(765, 65, 0)</td>\n",
       "      <td>(50, 49, 0)</td>\n",
       "      <td>(96, 98, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>39</td>\n",
       "      <td>115.416252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1020, 58, 0)</td>\n",
       "      <td>(1075, 92, 0)</td>\n",
       "      <td>(15550, 77, 0)</td>\n",
       "      <td>(775, 62, 0)</td>\n",
       "      <td>(50, 51, 0)</td>\n",
       "      <td>(89, 98, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>40</td>\n",
       "      <td>120.413619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1030, 54, 0)</td>\n",
       "      <td>(1065, 92, 0)</td>\n",
       "      <td>(15450, 76, 0)</td>\n",
       "      <td>(775, 61, 0)</td>\n",
       "      <td>(50, 54, 0)</td>\n",
       "      <td>(92, 98, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>41</td>\n",
       "      <td>180.950586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1025, 54, 0)</td>\n",
       "      <td>(1065, 92, 0)</td>\n",
       "      <td>(15250, 76, 0)</td>\n",
       "      <td>(780, 59, 0)</td>\n",
       "      <td>(50, 53, 0)</td>\n",
       "      <td>(90, 98, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>42</td>\n",
       "      <td>165.149272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1035, 52, 0)</td>\n",
       "      <td>(1070, 91, 0)</td>\n",
       "      <td>(15400, 77, 0)</td>\n",
       "      <td>(785, 58, 0)</td>\n",
       "      <td>(50, 51, 0)</td>\n",
       "      <td>(89, 98, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>43</td>\n",
       "      <td>117.959584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1090, 53, 0)</td>\n",
       "      <td>(1075, 91, 0)</td>\n",
       "      <td>(15100, 78, 0)</td>\n",
       "      <td>(790, 59, 0)</td>\n",
       "      <td>(50, 55, 0)</td>\n",
       "      <td>(100, 98, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2021-12-08</td>\n",
       "      <td>44</td>\n",
       "      <td>121.260902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1085, 46, 0)</td>\n",
       "      <td>(1080, 92, 0)</td>\n",
       "      <td>(15575, 75, 0)</td>\n",
       "      <td>(805, 60, 0)</td>\n",
       "      <td>(50, 53, 0)</td>\n",
       "      <td>(100, 97, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2021-12-09</td>\n",
       "      <td>45</td>\n",
       "      <td>112.851907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1075, 46, 0)</td>\n",
       "      <td>(1090, 93, 0)</td>\n",
       "      <td>(15725, 73, 0)</td>\n",
       "      <td>(795, 62, 0)</td>\n",
       "      <td>(50, 52, 0)</td>\n",
       "      <td>(101, 97, 0)</td>\n",
       "      <td>1092406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>46</td>\n",
       "      <td>59.907972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1060, 39, 39)</td>\n",
       "      <td>(1090, 94, 94)</td>\n",
       "      <td>(15950, 72, 59)</td>\n",
       "      <td>(795, 64, 8)</td>\n",
       "      <td>(50, 53, 2)</td>\n",
       "      <td>(105, 97, 0)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>47</td>\n",
       "      <td>99.784454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1060, 89, 0)</td>\n",
       "      <td>(1105, 86, 0)</td>\n",
       "      <td>(15775, 74, 0)</td>\n",
       "      <td>(795, 30, 0)</td>\n",
       "      <td>(50, 51, 0)</td>\n",
       "      <td>(121, 94, 0)</td>\n",
       "      <td>1081317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>48</td>\n",
       "      <td>79.198997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1040, 33, 33)</td>\n",
       "      <td>(1100, 93, 93)</td>\n",
       "      <td>(15350, 72, 61)</td>\n",
       "      <td>(795, 67, 9)</td>\n",
       "      <td>(50, 52, 2)</td>\n",
       "      <td>(151, 96, 0)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>49</td>\n",
       "      <td>64.221289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1025, 87, 33)</td>\n",
       "      <td>(1100, 84, 93)</td>\n",
       "      <td>(15625, 74, 61)</td>\n",
       "      <td>(800, 28, 9)</td>\n",
       "      <td>(50, 48, 2)</td>\n",
       "      <td>(151, 94, 0)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>50</td>\n",
       "      <td>217.606597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1010, 88, 0)</td>\n",
       "      <td>(1085, 85, 0)</td>\n",
       "      <td>(16175, 73, 0)</td>\n",
       "      <td>(795, 28, 0)</td>\n",
       "      <td>(50, 49, 0)</td>\n",
       "      <td>(151, 94, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>51</td>\n",
       "      <td>234.937038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(980, 28, 0)</td>\n",
       "      <td>(1090, 94, 0)</td>\n",
       "      <td>(15900, 73, 0)</td>\n",
       "      <td>(795, 71, 0)</td>\n",
       "      <td>(50, 49, 0)</td>\n",
       "      <td>(151, 96, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>52</td>\n",
       "      <td>239.463400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(925, 29, 0)</td>\n",
       "      <td>(1090, 94, 0)</td>\n",
       "      <td>(15775, 73, 0)</td>\n",
       "      <td>(795, 71, 0)</td>\n",
       "      <td>(50, 51, 0)</td>\n",
       "      <td>(151, 96, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>53</td>\n",
       "      <td>143.211276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(930, 29, 0)</td>\n",
       "      <td>(1110, 93, 0)</td>\n",
       "      <td>(15775, 71, 0)</td>\n",
       "      <td>(795, 69, 0)</td>\n",
       "      <td>(50, 51, 0)</td>\n",
       "      <td>(151, 96, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>54</td>\n",
       "      <td>116.074381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(905, 25, 0)</td>\n",
       "      <td>(1115, 93, 0)</td>\n",
       "      <td>(16475, 71, 0)</td>\n",
       "      <td>(810, 66, 0)</td>\n",
       "      <td>(50, 51, 0)</td>\n",
       "      <td>(151, 96, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>55</td>\n",
       "      <td>143.594687</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(885, 28, 0)</td>\n",
       "      <td>(1115, 94, 0)</td>\n",
       "      <td>(17650, 70, 0)</td>\n",
       "      <td>(805, 66, 0)</td>\n",
       "      <td>(50, 52, 0)</td>\n",
       "      <td>(151, 95, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>56</td>\n",
       "      <td>103.553118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(900, 27, 0)</td>\n",
       "      <td>(1120, 95, 0)</td>\n",
       "      <td>(17250, 69, 0)</td>\n",
       "      <td>(800, 69, 0)</td>\n",
       "      <td>(50, 55, 0)</td>\n",
       "      <td>(141, 95, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>57</td>\n",
       "      <td>106.628102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(960, 27, 0)</td>\n",
       "      <td>(1125, 95, 0)</td>\n",
       "      <td>(16825, 71, 0)</td>\n",
       "      <td>(810, 68, 0)</td>\n",
       "      <td>(50, 58, 0)</td>\n",
       "      <td>(137, 95, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>58</td>\n",
       "      <td>113.662820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(920, 28, 0)</td>\n",
       "      <td>(1135, 94, 0)</td>\n",
       "      <td>(17125, 74, 0)</td>\n",
       "      <td>(805, 71, 0)</td>\n",
       "      <td>(50, 57, 0)</td>\n",
       "      <td>(138, 96, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>59</td>\n",
       "      <td>123.081425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(910, 29, 0)</td>\n",
       "      <td>(1115, 94, 0)</td>\n",
       "      <td>(17125, 74, 0)</td>\n",
       "      <td>(810, 73, 0)</td>\n",
       "      <td>(50, 56, 0)</td>\n",
       "      <td>(139, 96, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>60</td>\n",
       "      <td>163.237228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(895, 29, 0)</td>\n",
       "      <td>(1115, 94, 0)</td>\n",
       "      <td>(16000, 75, 0)</td>\n",
       "      <td>(825, 74, 0)</td>\n",
       "      <td>(50, 59, 0)</td>\n",
       "      <td>(137, 96, 0)</td>\n",
       "      <td>1127049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  day  turbulence  sell_all            ADHI            APIC  \\\n",
       "0   2021-10-07    1  135.549417       1.0   (1095, 53, 0)    (870, 91, 0)   \n",
       "1   2021-10-08    2   71.242759       0.0  (1100, 52, 52)   (880, 90, 90)   \n",
       "2   2021-10-11    3  111.762992       1.0   (1090, 93, 0)    (875, 89, 0)   \n",
       "3   2021-10-12    4  104.749180       1.0   (1140, 49, 0)    (885, 89, 0)   \n",
       "4   2021-10-13    5  108.012925       1.0   (1150, 47, 0)    (900, 90, 0)   \n",
       "5   2021-10-14    6   99.055134       1.0   (1180, 42, 0)    (900, 89, 0)   \n",
       "6   2021-10-15    7   73.197749       0.0  (1185, 40, 40)   (910, 89, 89)   \n",
       "7   2021-10-18    8  108.583841       1.0   (1190, 91, 0)    (935, 88, 0)   \n",
       "8   2021-10-19    9  190.356449       1.0   (1190, 45, 0)    (950, 90, 0)   \n",
       "9   2021-10-21   10  256.420879       1.0   (1110, 48, 0)    (945, 90, 0)   \n",
       "10  2021-10-22   11  113.164301       1.0   (1155, 53, 0)    (950, 91, 0)   \n",
       "11  2021-10-25   12  106.783181       1.0   (1125, 51, 0)    (950, 90, 0)   \n",
       "12  2021-10-26   13  148.030183       1.0   (1095, 47, 0)    (965, 90, 0)   \n",
       "13  2021-10-27   14   85.271105       0.0  (1040, 48, 48)   (955, 91, 91)   \n",
       "14  2021-10-28   15   70.932055       0.0  (1020, 91, 48)   (940, 85, 91)   \n",
       "15  2021-10-29   16  236.089529       1.0   (1050, 90, 0)    (970, 83, 0)   \n",
       "16  2021-11-01   17  134.478367       1.0   (1060, 42, 0)    (975, 91, 0)   \n",
       "17  2021-11-02   18  148.687444       1.0   (1040, 42, 0)    (980, 89, 0)   \n",
       "18  2021-11-03   19  117.879127       1.0   (1100, 42, 0)    (980, 91, 0)   \n",
       "19  2021-11-04   20  118.487992       1.0   (1110, 47, 0)    (980, 91, 0)   \n",
       "20  2021-11-05   21   85.063194       0.0  (1085, 46, 46)   (995, 91, 91)   \n",
       "21  2021-11-08   22  125.648380       1.0   (1080, 91, 0)   (1015, 84, 0)   \n",
       "22  2021-11-09   23  168.597997       1.0   (1120, 44, 0)   (1030, 92, 0)   \n",
       "23  2021-11-10   24  136.224511       1.0   (1140, 41, 0)   (1040, 93, 0)   \n",
       "24  2021-11-11   25  183.822521       1.0   (1130, 41, 0)   (1030, 93, 0)   \n",
       "25  2021-11-12   26  180.512011       1.0   (1110, 43, 0)   (1025, 93, 0)   \n",
       "26  2021-11-15   27  107.574976       1.0   (1090, 42, 0)   (1020, 92, 0)   \n",
       "27  2021-11-16   28  149.493047       1.0   (1095, 46, 0)   (1030, 93, 0)   \n",
       "28  2021-11-17   29  193.747153       1.0   (1110, 48, 0)   (1015, 93, 0)   \n",
       "29  2021-11-18   30  202.796573       1.0   (1115, 50, 0)   (1010, 93, 0)   \n",
       "30  2021-11-19   31   87.849023       0.0  (1115, 52, 52)  (1015, 93, 93)   \n",
       "31  2021-11-22   32  182.972408       1.0   (1140, 90, 0)   (1015, 83, 0)   \n",
       "32  2021-11-23   33   86.750593       0.0  (1135, 51, 51)  (1005, 93, 93)   \n",
       "33  2021-11-24   34  104.754051       1.0   (1135, 91, 0)   (1010, 82, 0)   \n",
       "34  2021-11-25   35  134.225604       1.0   (1155, 53, 0)   (1045, 93, 0)   \n",
       "35  2021-11-26   36  119.054191       1.0   (1095, 54, 0)   (1040, 93, 0)   \n",
       "36  2021-11-29   37  123.803598       1.0   (1075, 54, 0)   (1050, 92, 0)   \n",
       "37  2021-11-30   38  159.324943       1.0   (1025, 55, 0)   (1090, 92, 0)   \n",
       "38  2021-12-01   39  115.416252       1.0   (1020, 58, 0)   (1075, 92, 0)   \n",
       "39  2021-12-02   40  120.413619       1.0   (1030, 54, 0)   (1065, 92, 0)   \n",
       "40  2021-12-03   41  180.950586       1.0   (1025, 54, 0)   (1065, 92, 0)   \n",
       "41  2021-12-06   42  165.149272       1.0   (1035, 52, 0)   (1070, 91, 0)   \n",
       "42  2021-12-07   43  117.959584       1.0   (1090, 53, 0)   (1075, 91, 0)   \n",
       "43  2021-12-08   44  121.260902       1.0   (1085, 46, 0)   (1080, 92, 0)   \n",
       "44  2021-12-09   45  112.851907       1.0   (1075, 46, 0)   (1090, 93, 0)   \n",
       "45  2021-12-10   46   59.907972       0.0  (1060, 39, 39)  (1090, 94, 94)   \n",
       "46  2021-12-13   47   99.784454       1.0   (1060, 89, 0)   (1105, 86, 0)   \n",
       "47  2021-12-14   48   79.198997       0.0  (1040, 33, 33)  (1100, 93, 93)   \n",
       "48  2021-12-15   49   64.221289       0.0  (1025, 87, 33)  (1100, 84, 93)   \n",
       "49  2021-12-16   50  217.606597       1.0   (1010, 88, 0)   (1085, 85, 0)   \n",
       "50  2021-12-17   51  234.937038       1.0    (980, 28, 0)   (1090, 94, 0)   \n",
       "51  2021-12-20   52  239.463400       1.0    (925, 29, 0)   (1090, 94, 0)   \n",
       "52  2021-12-21   53  143.211276       1.0    (930, 29, 0)   (1110, 93, 0)   \n",
       "53  2021-12-22   54  116.074381       1.0    (905, 25, 0)   (1115, 93, 0)   \n",
       "54  2021-12-23   55  143.594687       1.0    (885, 28, 0)   (1115, 94, 0)   \n",
       "55  2021-12-24   56  103.553118       1.0    (900, 27, 0)   (1120, 95, 0)   \n",
       "56  2021-12-27   57  106.628102       1.0    (960, 27, 0)   (1125, 95, 0)   \n",
       "57  2021-12-28   58  113.662820       1.0    (920, 28, 0)   (1135, 94, 0)   \n",
       "58  2021-12-29   59  123.081425       1.0    (910, 29, 0)   (1115, 94, 0)   \n",
       "59  2021-12-30   60  163.237228       1.0    (895, 29, 0)   (1115, 94, 0)   \n",
       "\n",
       "               ARTO           ASGR          BAPI          TMAS  \\\n",
       "0    (13125, 81, 0)   (760, 61, 0)   (50, 19, 0)   (31, 98, 0)   \n",
       "1   (12925, 83, 66)  (760, 65, 12)   (50, 16, 8)   (31, 98, 0)   \n",
       "2    (12350, 63, 0)   (735, 25, 0)   (50, 35, 0)   (30, 97, 0)   \n",
       "3    (12700, 82, 0)   (740, 61, 0)   (50, 14, 0)   (31, 98, 0)   \n",
       "4    (12250, 81, 0)   (740, 61, 0)   (50, 13, 0)   (30, 98, 0)   \n",
       "5    (12375, 82, 0)   (730, 63, 0)   (50, 10, 0)   (31, 98, 0)   \n",
       "6   (13125, 80, 63)   (720, 63, 3)   (50, 14, 8)   (31, 98, 1)   \n",
       "7    (13425, 64, 0)   (710, 23, 0)   (50, 34, 0)   (31, 97, 0)   \n",
       "8    (13825, 76, 0)   (710, 62, 0)   (50, 23, 0)   (31, 98, 0)   \n",
       "9    (14750, 75, 0)   (705, 62, 0)   (50, 28, 0)   (31, 98, 0)   \n",
       "10   (14900, 73, 0)   (710, 60, 0)   (50, 45, 0)   (31, 98, 0)   \n",
       "11   (14925, 73, 0)   (720, 61, 0)   (50, 45, 0)   (31, 98, 0)   \n",
       "12   (15175, 72, 0)   (725, 62, 0)   (50, 41, 0)   (31, 98, 0)   \n",
       "13  (14825, 70, 56)  (735, 63, 13)  (50, 42, 12)   (32, 98, 0)   \n",
       "14  (14850, 65, 56)  (730, 21, 13)  (50, 47, 12)   (31, 96, 0)   \n",
       "15   (15500, 67, 0)   (725, 23, 0)   (50, 51, 0)   (31, 96, 0)   \n",
       "16   (15000, 72, 0)   (725, 66, 0)   (50, 50, 0)   (32, 98, 0)   \n",
       "17   (15300, 75, 0)   (735, 65, 0)   (50, 50, 0)   (31, 98, 0)   \n",
       "18   (15400, 73, 0)   (740, 70, 0)   (50, 47, 0)   (31, 98, 0)   \n",
       "19   (15200, 72, 0)   (740, 64, 0)   (50, 49, 0)   (39, 98, 0)   \n",
       "20  (15175, 71, 57)  (755, 65, 12)   (50, 47, 3)   (37, 98, 1)   \n",
       "21   (16025, 70, 0)   (765, 28, 0)   (50, 52, 0)   (39, 96, 0)   \n",
       "22   (16725, 70, 0)   (775, 68, 0)   (50, 51, 0)   (49, 97, 0)   \n",
       "23   (16425, 70, 0)   (770, 68, 0)   (50, 52, 0)   (48, 98, 0)   \n",
       "24   (16275, 71, 0)   (775, 67, 0)   (50, 54, 0)   (60, 98, 0)   \n",
       "25   (15500, 69, 0)   (765, 64, 0)   (50, 56, 0)   (61, 98, 0)   \n",
       "26   (15625, 72, 0)   (775, 64, 0)   (50, 54, 0)   (60, 97, 0)   \n",
       "27   (15825, 69, 0)   (780, 63, 0)   (50, 53, 0)   (62, 97, 0)   \n",
       "28   (15800, 68, 0)   (790, 61, 0)   (50, 55, 0)   (63, 97, 0)   \n",
       "29   (15450, 69, 0)   (785, 58, 0)   (50, 57, 0)   (64, 97, 0)   \n",
       "30  (15500, 71, 58)  (790, 57, 14)   (50, 52, 5)   (76, 97, 0)   \n",
       "31   (15500, 73, 0)   (800, 23, 0)   (50, 41, 0)   (71, 96, 0)   \n",
       "32  (14700, 70, 62)  (800, 58, -1)   (50, 49, 1)   (66, 97, 0)   \n",
       "33   (15200, 74, 0)   (800, 27, 0)   (50, 46, 0)   (67, 96, 0)   \n",
       "34   (15200, 73, 0)   (805, 62, 0)   (50, 50, 0)   (73, 98, 0)   \n",
       "35   (14750, 74, 0)   (795, 66, 0)   (50, 45, 0)   (70, 97, 0)   \n",
       "36   (15375, 76, 0)   (780, 66, 0)   (50, 47, 0)   (80, 98, 0)   \n",
       "37   (15825, 77, 0)   (765, 65, 0)   (50, 49, 0)   (96, 98, 0)   \n",
       "38   (15550, 77, 0)   (775, 62, 0)   (50, 51, 0)   (89, 98, 0)   \n",
       "39   (15450, 76, 0)   (775, 61, 0)   (50, 54, 0)   (92, 98, 0)   \n",
       "40   (15250, 76, 0)   (780, 59, 0)   (50, 53, 0)   (90, 98, 0)   \n",
       "41   (15400, 77, 0)   (785, 58, 0)   (50, 51, 0)   (89, 98, 0)   \n",
       "42   (15100, 78, 0)   (790, 59, 0)   (50, 55, 0)  (100, 98, 0)   \n",
       "43   (15575, 75, 0)   (805, 60, 0)   (50, 53, 0)  (100, 97, 0)   \n",
       "44   (15725, 73, 0)   (795, 62, 0)   (50, 52, 0)  (101, 97, 0)   \n",
       "45  (15950, 72, 59)   (795, 64, 8)   (50, 53, 2)  (105, 97, 0)   \n",
       "46   (15775, 74, 0)   (795, 30, 0)   (50, 51, 0)  (121, 94, 0)   \n",
       "47  (15350, 72, 61)   (795, 67, 9)   (50, 52, 2)  (151, 96, 0)   \n",
       "48  (15625, 74, 61)   (800, 28, 9)   (50, 48, 2)  (151, 94, 0)   \n",
       "49   (16175, 73, 0)   (795, 28, 0)   (50, 49, 0)  (151, 94, 0)   \n",
       "50   (15900, 73, 0)   (795, 71, 0)   (50, 49, 0)  (151, 96, 0)   \n",
       "51   (15775, 73, 0)   (795, 71, 0)   (50, 51, 0)  (151, 96, 0)   \n",
       "52   (15775, 71, 0)   (795, 69, 0)   (50, 51, 0)  (151, 96, 0)   \n",
       "53   (16475, 71, 0)   (810, 66, 0)   (50, 51, 0)  (151, 96, 0)   \n",
       "54   (17650, 70, 0)   (805, 66, 0)   (50, 52, 0)  (151, 95, 0)   \n",
       "55   (17250, 69, 0)   (800, 69, 0)   (50, 55, 0)  (141, 95, 0)   \n",
       "56   (16825, 71, 0)   (810, 68, 0)   (50, 58, 0)  (137, 95, 0)   \n",
       "57   (17125, 74, 0)   (805, 71, 0)   (50, 57, 0)  (138, 96, 0)   \n",
       "58   (17125, 74, 0)   (810, 73, 0)   (50, 56, 0)  (139, 96, 0)   \n",
       "59   (16000, 75, 0)   (825, 74, 0)   (50, 59, 0)  (137, 96, 0)   \n",
       "\n",
       "    funds_on_market_close  \n",
       "0                 1000000  \n",
       "1                      31  \n",
       "2                  958821  \n",
       "3                  958821  \n",
       "4                  958821  \n",
       "5                  958821  \n",
       "6                       7  \n",
       "7                  978179  \n",
       "8                  978179  \n",
       "9                  978179  \n",
       "10                 978179  \n",
       "11                 978179  \n",
       "12                 978179  \n",
       "13                     22  \n",
       "14                     22  \n",
       "15                1015700  \n",
       "16                1015700  \n",
       "17                1015700  \n",
       "18                1015700  \n",
       "19                1015700  \n",
       "20                      8  \n",
       "21                1063783  \n",
       "22                1063783  \n",
       "23                1063783  \n",
       "24                1063783  \n",
       "25                1063783  \n",
       "26                1063783  \n",
       "27                1063783  \n",
       "28                1063783  \n",
       "29                1063783  \n",
       "30                     35  \n",
       "31                1063096  \n",
       "32                     34  \n",
       "33                1092406  \n",
       "34                1092406  \n",
       "35                1092406  \n",
       "36                1092406  \n",
       "37                1092406  \n",
       "38                1092406  \n",
       "39                1092406  \n",
       "40                1092406  \n",
       "41                1092406  \n",
       "42                1092406  \n",
       "43                1092406  \n",
       "44                1092406  \n",
       "45                      5  \n",
       "46                1081317  \n",
       "47                     12  \n",
       "48                     12  \n",
       "49                1127049  \n",
       "50                1127049  \n",
       "51                1127049  \n",
       "52                1127049  \n",
       "53                1127049  \n",
       "54                1127049  \n",
       "55                1127049  \n",
       "56                1127049  \n",
       "57                1127049  \n",
       "58                1127049  \n",
       "59                1127049  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_action = env_instance.history_action\n",
    "history_amount = env_instance.history_amount\n",
    "turbulence_bool = env_instance.turbulence_bool\n",
    "excel_file = \"/mnt/c/Users/mahfu/Downloads/tuntun/tuntun_ubuntu/github_me/finrl/from_finrl-tutorials_git/papertrading_erl/detailed_actions_local.xlsx\"\n",
    "create_detailed_actions_excel(\n",
    "    excel_file, tickers, history_action, \n",
    "    history_amount, test_turbulence_array, \n",
    "    turbulence_bool, test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b3443e-9b07-4b94-b59b-773c9ad51f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "def create_detailed_actions_excel(\n",
    "    excel_path: str, tickers: List[str], \n",
    "    history_action: Dict, history_amount: Dict, \n",
    "    turbulence_array: List, turbulence_bool: List,\n",
    "    dates: List\n",
    "):\n",
    "    \"\"\"\n",
    "    Create an Excel file with detailed trading actions for tickers bought at least once.\n",
    "\n",
    "    Parameters:\n",
    "    - tickers: NumPy array or list of ticker symbols\n",
    "    - history_action: Dictionary of actions for each day\n",
    "    - history_amount: Dictionary of amount of money at the end of each market close\n",
    "    - turbulence_array: List of the value of turbulence calculation for each day\n",
    "    - turbulence_bool: List of boolean flag that determines whether we sell all stocks / not for today trade \n",
    "    (if turbulence_array value > turbulence_threshold=99, then turbulence_bool is set to True)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with detailed actions\n",
    "    \"\"\"\n",
    "    # Convert tickers to a list if it's a NumPy array\n",
    "    tickers_list = tickers.tolist() if hasattr(tickers, 'tolist') else list(tickers)\n",
    "\n",
    "    # Find tickers that have been bought at least once\n",
    "    bought_tickers = set()\n",
    "\n",
    "    # Iterate through all days and actions to find bought tickers\n",
    "    for day_actions in history_action.values():\n",
    "        for idx, action_tuple in enumerate(day_actions):\n",
    "            # Check if the stock was bought (positive number of stocks purchased)\n",
    "            if len(action_tuple) >= 3 and action_tuple[1] > 0 and action_tuple[2] > 0:\n",
    "                bought_tickers.add(tickers_list[idx])\n",
    "\n",
    "    # Convert to sorted list for consistent ordering\n",
    "    bought_tickers = sorted(list(bought_tickers))\n",
    "\n",
    "    # Prepare the columns\n",
    "    columns = ['date', 'day', 'turbulence', 'sell_all'] + list(bought_tickers) + ['funds_on_market_close']\n",
    "\n",
    "    # Create a list to store data for each day\n",
    "    data_rows = []\n",
    "\n",
    "    # Iterate through days in the history_action\n",
    "    for day, day_actions in history_action.items():\n",
    "\n",
    "        # Add turbulence value on that day\n",
    "        # turbulence = turbulence_array.get(day, np.nan)\n",
    "        day_index = day\n",
    "        turbulence = turbulence_array[day_index] if day_index < len(turbulence_array) else np.nan\n",
    "\n",
    "        # Add turbulence bool on that day\n",
    "        # sell_all = turbulence_bool.get(day, np.nan)\n",
    "        sell_all = turbulence_bool[day_index] if day_index < len(turbulence_bool) else np.nan\n",
    "\n",
    "        # Create a row for this day\n",
    "        row_data = [dates[day], day, turbulence, sell_all]\n",
    "\n",
    "        # Add actions for bought tickers\n",
    "        day_bought_actions = []\n",
    "        for ticker in bought_tickers:\n",
    "            # Find the index of the ticker in the original tickers list\n",
    "            ticker_index = tickers_list.index(ticker)\n",
    "\n",
    "            # Get the action for this specific ticker\n",
    "            if ticker_index < len(day_actions):\n",
    "                day_bought_actions.append(day_actions[ticker_index])\n",
    "            else:\n",
    "                # Pad with default value if not enough actions\n",
    "                day_bought_actions.append((0, 0, 0))\n",
    "\n",
    "        # Extend row with bought ticker actions\n",
    "        row_data.extend(day_bought_actions)\n",
    "\n",
    "        # Add amount of money at market close\n",
    "        row_data.append(history_amount.get(day, np.nan))\n",
    "\n",
    "        # Append the row to data\n",
    "        data_rows.append(row_data)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data_rows, columns=columns)\n",
    "\n",
    "    # Save to Excel\n",
    "    df.to_excel(excel_file, sheet_name='detailed_actions', index=False)\n",
    "\n",
    "    print(f\"Detailed actions is saved to\\n{excel_file}\")\n",
    "    print(f\"Number of tickers with at least one buy action: {len(bought_tickers)}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# # Call the function with the provided variables\n",
    "# # Assuming tickers, history_action, and history_amount are already defined\n",
    "# result_df = create_detailed_actions_excel(tickers, history_action, history_amount)\n",
    "\n",
    "# # Optional: Display first few rows to verify\n",
    "# print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97dcfb6f-f2b8-440a-873e-e958de65ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def df_to_array(df, tech_indicator_list):\n",
    "    df = df.copy()\n",
    "    dates = sorted(df[\"date\"].unique())\n",
    "    unique_ticker = df.tic.unique()\n",
    "    if_first_time = True\n",
    "    for tic in unique_ticker:\n",
    "        if if_first_time:\n",
    "            price_array = df[df.tic == tic][[\"close\"]].values\n",
    "            tech_array = df[df.tic == tic][tech_indicator_list].values\n",
    "            turbulence_array = df[df.tic == tic][\"turbulence\"].values\n",
    "            if_first_time = False\n",
    "        else:\n",
    "            price_array = np.hstack(\n",
    "                [price_array, df[df.tic == tic][[\"close\"]].values]\n",
    "            )\n",
    "            tech_array = np.hstack(\n",
    "                [tech_array, df[df.tic == tic][tech_indicator_list].values]\n",
    "            )\n",
    "    tech_nan_positions = np.isnan(tech_array)\n",
    "    tech_array[tech_nan_positions] = 0\n",
    "    tech_inf_positions = np.isinf(tech_array)\n",
    "    tech_array[tech_inf_positions] = 0\n",
    "    return price_array, tech_array, turbulence_array, unique_ticker, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6d07bdb-0e15-42e0-8433-a46531e5d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def df_to_array(df, tech_indicator_list):\n",
    "#     df = df.copy()\n",
    "#     unique_ticker = df.tic.unique()\n",
    "#     if_first_time = True\n",
    "#     for tic in unique_ticker:\n",
    "#         if if_first_time:\n",
    "#             price_array = df[df.tic == tic][[\"close\"]].values\n",
    "#             tech_array = df[df.tic == tic][tech_indicator_list].values\n",
    "#             turbulence_array = df[df.tic == tic][\"turbulence\"].values\n",
    "#             if_first_time = False\n",
    "#         else:\n",
    "#             price_array = np.hstack(\n",
    "#                 [price_array, df[df.tic == tic][[\"close\"]].values]\n",
    "#             )\n",
    "#             tech_array = np.hstack(\n",
    "#                 [tech_array, df[df.tic == tic][tech_indicator_list].values]\n",
    "#             )\n",
    "#     tech_nan_positions = np.isnan(tech_array)\n",
    "#     tech_array[tech_nan_positions] = 0\n",
    "#     tech_inf_positions = np.isinf(tech_array)\n",
    "#     tech_array[tech_inf_positions] = 0\n",
    "#     return price_array, tech_array, turbulence_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "667688ec-343b-4b3f-930d-f21c6e1c6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from torch import Tensor\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "\n",
    "class ActorPPO(nn.Module):\n",
    "    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n",
    "        self.action_std_log = nn.Parameter(torch.zeros((1, action_dim)), requires_grad=True)  # trainable parameter\n",
    "\n",
    "    def forward(self, state: Tensor) -> Tensor:\n",
    "        return self.net(state).tanh()  # action.tanh()\n",
    "\n",
    "    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration\n",
    "        action_avg = self.net(state)\n",
    "        action_std = self.action_std_log.exp()\n",
    "\n",
    "        dist = Normal(action_avg, action_std)\n",
    "        action = dist.sample()\n",
    "        logprob = dist.log_prob(action).sum(1)\n",
    "        return action, logprob\n",
    "\n",
    "    def get_logprob_entropy(self, state: Tensor, action: Tensor) -> (Tensor, Tensor):\n",
    "        action_avg = self.net(state)\n",
    "        action_std = self.action_std_log.exp()\n",
    "\n",
    "        dist = Normal(action_avg, action_std)\n",
    "        logprob = dist.log_prob(action).sum(1)\n",
    "        entropy = dist.entropy().sum(1)\n",
    "        return logprob, entropy\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_action_for_env(action: Tensor) -> Tensor:\n",
    "        return action.tanh()\n",
    "\n",
    "\n",
    "class CriticPPO(nn.Module):\n",
    "    def __init__(self, dims: [int], state_dim: int, _action_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = build_mlp(dims=[state_dim, *dims, 1])\n",
    "\n",
    "    def forward(self, state: Tensor) -> Tensor:\n",
    "        return self.net(state)  # advantage value\n",
    "\n",
    "\n",
    "def build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n",
    "    net_list = []\n",
    "    for i in range(len(dims) - 1):\n",
    "        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])\n",
    "    del net_list[-1]  # remove the activation of output layer\n",
    "    return nn.Sequential(*net_list)\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, agent_class=None, env_class=None, env_args=None):\n",
    "        self.env_class = env_class  # env = env_class(**env_args)\n",
    "        self.env_args = env_args  # env = env_class(**env_args)\n",
    "\n",
    "        if env_args is None:  # dummy env_args\n",
    "            env_args = {'env_name': None, 'state_dim': None, 'action_dim': None, 'if_discrete': None}\n",
    "        self.env_name = env_args['env_name']  # the name of environment. Be used to set 'cwd'.\n",
    "        self.state_dim = env_args['state_dim']  # vector dimension (feature number) of state\n",
    "        self.action_dim = env_args['action_dim']  # vector dimension (feature number) of action\n",
    "        self.if_discrete = env_args['if_discrete']  # discrete or continuous action space\n",
    "\n",
    "        self.agent_class = agent_class  # agent = agent_class(...)\n",
    "\n",
    "        '''Arguments for reward shaping'''\n",
    "        self.gamma = 0.99  # discount factor of future rewards\n",
    "        self.reward_scale = 1.0  # an approximate target reward usually be closed to 256\n",
    "\n",
    "        '''Arguments for training'''\n",
    "        self.gpu_id = int(0)  # `int` means the ID of single GPU, -1 means CPU\n",
    "        self.net_dims = (64, 32)  # the middle layer dimension of MLP (MultiLayer Perceptron)\n",
    "        self.learning_rate = 6e-5  # 2 ** -14 ~= 6e-5\n",
    "        self.soft_update_tau = 5e-3  # 2 ** -8 ~= 5e-3\n",
    "        self.batch_size = int(128)  # num of transitions sampled from replay buffer.\n",
    "        self.horizon_len = int(2000)  # collect horizon_len step while exploring, then update network\n",
    "        self.buffer_size = None  # ReplayBuffer size. Empty the ReplayBuffer for on-policy.\n",
    "        self.repeat_times = 8.0  # repeatedly update network using ReplayBuffer to keep critic's loss small\n",
    "\n",
    "        '''Arguments for evaluate'''\n",
    "        self.cwd = None  # current working directory to save model. None means set automatically\n",
    "        self.break_step = +np.inf  # break training if 'total_step > break_step'\n",
    "        self.eval_times = int(32)  # number of times that get episodic cumulative return\n",
    "        self.eval_per_step = int(2e4)  # evaluate the agent per training steps\n",
    "\n",
    "    def init_before_training(self):\n",
    "        if self.cwd is None:  # set cwd (current working directory) for saving model\n",
    "            self.cwd = f'./{self.env_name}_{self.agent_class.__name__[5:]}'\n",
    "        os.makedirs(self.cwd, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_gym_env_args(env, if_print: bool) -> dict:\n",
    "    if {'unwrapped', 'observation_space', 'action_space', 'spec'}.issubset(dir(env)):  # isinstance(env, gym.Env):\n",
    "        env_name = env.unwrapped.spec.id\n",
    "        state_shape = env.observation_space.shape\n",
    "        state_dim = state_shape[0] if len(state_shape) == 1 else state_shape  # sometimes state_dim is a list\n",
    "\n",
    "        if_discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "        if if_discrete:  # make sure it is discrete action space\n",
    "            action_dim = env.action_space.n\n",
    "        elif isinstance(env.action_space, gym.spaces.Box):  # make sure it is continuous action space\n",
    "            action_dim = env.action_space.shape[0]\n",
    "\n",
    "    env_args = {'env_name': env_name, 'state_dim': state_dim, 'action_dim': action_dim, 'if_discrete': if_discrete}\n",
    "    print(f\"env_args = {repr(env_args)}\") if if_print else None\n",
    "    return env_args\n",
    "\n",
    "\n",
    "def kwargs_filter(function, kwargs: dict) -> dict:\n",
    "    import inspect\n",
    "    sign = inspect.signature(function).parameters.values()\n",
    "    sign = {val.name for val in sign}\n",
    "    common_args = sign.intersection(kwargs.keys())\n",
    "    return {key: kwargs[key] for key in common_args}  # filtered kwargs\n",
    "\n",
    "\n",
    "def build_env(env_class=None, env_args=None):\n",
    "    if env_class.__module__ == 'gym.envs.registration':  # special rule\n",
    "        env = env_class(id=env_args['env_name'])\n",
    "    else:\n",
    "        env = env_class(**kwargs_filter(env_class.__init__, env_args.copy()))\n",
    "    for attr_str in ('env_name', 'state_dim', 'action_dim', 'if_discrete'):\n",
    "        setattr(env, attr_str, env_args[attr_str])\n",
    "    return env\n",
    "\n",
    "\n",
    "class AgentBase:\n",
    "    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "        self.gamma = args.gamma\n",
    "        self.batch_size = args.batch_size\n",
    "        self.repeat_times = args.repeat_times\n",
    "        self.reward_scale = args.reward_scale\n",
    "        self.soft_update_tau = args.soft_update_tau\n",
    "\n",
    "        self.states = None  # assert self.states == (1, state_dim)\n",
    "        self.device = torch.device(f\"cuda:{gpu_id}\" if (torch.cuda.is_available() and (gpu_id >= 0)) else \"cpu\")\n",
    "\n",
    "        act_class = getattr(self, \"act_class\", None)\n",
    "        cri_class = getattr(self, \"cri_class\", None)\n",
    "        self.act = self.act_target = act_class(net_dims, state_dim, action_dim).to(self.device)\n",
    "        self.cri = self.cri_target = cri_class(net_dims, state_dim, action_dim).to(self.device) \\\n",
    "            if cri_class else self.act\n",
    "\n",
    "        self.act_optimizer = torch.optim.Adam(self.act.parameters(), args.learning_rate)\n",
    "        self.cri_optimizer = torch.optim.Adam(self.cri.parameters(), args.learning_rate) \\\n",
    "            if cri_class else self.act_optimizer\n",
    "        self.criterion = torch.nn.SmoothL1Loss()\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer_update(optimizer, objective: Tensor):\n",
    "        optimizer.zero_grad()\n",
    "        objective.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    @staticmethod\n",
    "    def soft_update(target_net: torch.nn.Module, current_net: torch.nn.Module, tau: float):\n",
    "        for tar, cur in zip(target_net.parameters(), current_net.parameters()):\n",
    "            tar.data.copy_(cur.data * tau + tar.data * (1.0 - tau))\n",
    "\n",
    "\n",
    "class AgentPPO(AgentBase):\n",
    "    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n",
    "        self.if_off_policy = False\n",
    "        self.act_class = getattr(self, \"act_class\", ActorPPO)\n",
    "        self.cri_class = getattr(self, \"cri_class\", CriticPPO)\n",
    "        AgentBase.__init__(self, net_dims, state_dim, action_dim, gpu_id, args)\n",
    "\n",
    "        self.ratio_clip = getattr(args, \"ratio_clip\", 0.25)  # `ratio.clamp(1 - clip, 1 + clip)`\n",
    "        self.lambda_gae_adv = getattr(args, \"lambda_gae_adv\", 0.95)  # could be 0.80~0.99\n",
    "        self.lambda_entropy = getattr(args, \"lambda_entropy\", 0.01)  # could be 0.00~0.10\n",
    "        self.lambda_entropy = torch.tensor(self.lambda_entropy, dtype=torch.float32, device=self.device)\n",
    "\n",
    "    def explore_env(self, env, horizon_len: int) -> [Tensor]:\n",
    "        states = torch.zeros((horizon_len, self.state_dim), dtype=torch.float32).to(self.device)\n",
    "        actions = torch.zeros((horizon_len, self.action_dim), dtype=torch.float32).to(self.device)\n",
    "        logprobs = torch.zeros(horizon_len, dtype=torch.float32).to(self.device)\n",
    "        rewards = torch.zeros(horizon_len, dtype=torch.float32).to(self.device)\n",
    "        dones = torch.zeros(horizon_len, dtype=torch.bool).to(self.device)\n",
    "\n",
    "        ary_state = self.states[0]\n",
    "\n",
    "        get_action = self.act.get_action\n",
    "        convert = self.act.convert_action_for_env\n",
    "        for i in range(horizon_len):\n",
    "            state = torch.as_tensor(ary_state, dtype=torch.float32, device=self.device)\n",
    "            action, logprob = [t.squeeze(0) for t in get_action(state.unsqueeze(0))[:2]]\n",
    "\n",
    "            ary_action = convert(action).detach().cpu().numpy()\n",
    "            ary_state, reward, done, _, _ = env.step(ary_action)\n",
    "            if done:\n",
    "                ary_state, _ = env.reset()\n",
    "\n",
    "            states[i] = state\n",
    "            actions[i] = action\n",
    "            logprobs[i] = logprob\n",
    "            rewards[i] = reward\n",
    "            dones[i] = done\n",
    "\n",
    "        self.states[0] = ary_state\n",
    "        rewards = (rewards * self.reward_scale).unsqueeze(1)\n",
    "        undones = (1 - dones.type(torch.float32)).unsqueeze(1)\n",
    "        return states, actions, logprobs, rewards, undones\n",
    "\n",
    "    def update_net(self, buffer) -> [float]:\n",
    "        with torch.no_grad():\n",
    "            states, actions, logprobs, rewards, undones = buffer\n",
    "            buffer_size = states.shape[0]\n",
    "\n",
    "            '''get advantages reward_sums'''\n",
    "            bs = 2 ** 10  # set a smaller 'batch_size' when out of GPU memory.\n",
    "            values = [self.cri(states[i:i + bs]) for i in range(0, buffer_size, bs)]\n",
    "            values = torch.cat(values, dim=0).squeeze(1)  # values.shape == (buffer_size, )\n",
    "\n",
    "            advantages = self.get_advantages(rewards, undones, values)  # advantages.shape == (buffer_size, )\n",
    "            reward_sums = advantages + values  # reward_sums.shape == (buffer_size, )\n",
    "            del rewards, undones, values\n",
    "\n",
    "            advantages = (advantages - advantages.mean()) / (advantages.std(dim=0) + 1e-5)\n",
    "        assert logprobs.shape == advantages.shape == reward_sums.shape == (buffer_size,)\n",
    "        '''update network'''\n",
    "        obj_critics = 0.0\n",
    "        obj_actors = 0.0\n",
    "\n",
    "        update_times = int(buffer_size * self.repeat_times / self.batch_size)\n",
    "        assert update_times >= 1\n",
    "        for _ in range(update_times):\n",
    "            indices = torch.randint(buffer_size, size=(self.batch_size,), requires_grad=False)\n",
    "            state = states[indices]\n",
    "            action = actions[indices]\n",
    "            logprob = logprobs[indices]\n",
    "            advantage = advantages[indices]\n",
    "            reward_sum = reward_sums[indices]\n",
    "\n",
    "            value = self.cri(state).squeeze(1)  # critic network predicts the reward_sum (Q value) of state\n",
    "            obj_critic = self.criterion(value, reward_sum)\n",
    "            self.optimizer_update(self.cri_optimizer, obj_critic)\n",
    "\n",
    "            new_logprob, obj_entropy = self.act.get_logprob_entropy(state, action)\n",
    "            ratio = (new_logprob - logprob.detach()).exp()\n",
    "            surrogate1 = advantage * ratio\n",
    "            surrogate2 = advantage * ratio.clamp(1 - self.ratio_clip, 1 + self.ratio_clip)\n",
    "            obj_surrogate = torch.min(surrogate1, surrogate2).mean()\n",
    "\n",
    "            obj_actor = obj_surrogate + obj_entropy.mean() * self.lambda_entropy\n",
    "            self.optimizer_update(self.act_optimizer, -obj_actor)\n",
    "\n",
    "            obj_critics += obj_critic.item()\n",
    "            obj_actors += obj_actor.item()\n",
    "        a_std_log = getattr(self.act, 'a_std_log', torch.zeros(1)).mean()\n",
    "        return obj_critics / update_times, obj_actors / update_times, a_std_log.item()\n",
    "\n",
    "    def get_advantages(self, rewards: Tensor, undones: Tensor, values: Tensor) -> Tensor:\n",
    "        advantages = torch.empty_like(values)  # advantage value\n",
    "\n",
    "        masks = undones * self.gamma\n",
    "        horizon_len = rewards.shape[0]\n",
    "\n",
    "        next_state = torch.tensor(self.states, dtype=torch.float32).to(self.device)\n",
    "        next_value = self.cri(next_state).detach()[0, 0]\n",
    "\n",
    "        advantage = 0  # last_gae_lambda\n",
    "        for t in range(horizon_len - 1, -1, -1):\n",
    "            delta = rewards[t] + masks[t] * next_value - values[t]\n",
    "            advantages[t] = advantage = delta + masks[t] * self.lambda_gae_adv * advantage\n",
    "            next_value = values[t]\n",
    "        return advantages\n",
    "\n",
    "class PendulumEnv(gym.Wrapper):  # a demo of custom gym env\n",
    "    def __init__(self):\n",
    "        gym.logger.set_level(40)  # Block warning\n",
    "        gym_env_name = \"Pendulum-v0\" if gym.__version__ < '0.18.0' else \"Pendulum-v1\"\n",
    "        super().__init__(env=gym.make(gym_env_name))\n",
    "\n",
    "        '''the necessary env information when you design a custom env'''\n",
    "        self.env_name = gym_env_name  # the name of this env.\n",
    "        self.state_dim = self.observation_space.shape[0]  # feature number of state\n",
    "        self.action_dim = self.action_space.shape[0]  # feature number of action\n",
    "        self.if_discrete = False  # discrete action or continuous action\n",
    "\n",
    "    def reset(self) -> np.ndarray:  # reset the agent in env\n",
    "        resetted_env, _ = self.env.reset()\n",
    "        return resetted_env\n",
    "\n",
    "    def step(self, action: np.ndarray) -> (np.ndarray, float, bool, dict):  # agent interacts in env\n",
    "        # We suggest that adjust action space to (-1, +1) when designing a custom env.\n",
    "        state, reward, done, info_dict, _ = self.env.step(action * 2)\n",
    "        return state.reshape(self.state_dim), float(reward), done, info_dict\n",
    "\n",
    "    \n",
    "def train_agent(args: Config):\n",
    "    args.init_before_training()\n",
    "\n",
    "    env = build_env(args.env_class, args.env_args)\n",
    "    agent = args.agent_class(args.net_dims, args.state_dim, args.action_dim, gpu_id=args.gpu_id, args=args)\n",
    "\n",
    "    new_env, _ = env.reset()\n",
    "    agent.states = new_env[np.newaxis, :]\n",
    "\n",
    "    evaluator = Evaluator(eval_env=build_env(args.env_class, args.env_args),\n",
    "                          eval_per_step=args.eval_per_step,\n",
    "                          eval_times=args.eval_times,\n",
    "                          cwd=args.cwd)\n",
    "    torch.set_grad_enabled(False)\n",
    "    while True: # start training\n",
    "        buffer_items = agent.explore_env(env, args.horizon_len)\n",
    "        torch.set_grad_enabled(True)\n",
    "        logging_tuple = agent.update_net(buffer_items)\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        evaluator.evaluate_and_save(agent.act, args.horizon_len, logging_tuple)\n",
    "        if (evaluator.total_step > args.break_step) or os.path.exists(f\"{args.cwd}/stop\"):\n",
    "            torch.save(agent.act.state_dict(), args.cwd + '/actor.pth')\n",
    "            break  # stop training when reach `break_step` or `mkdir cwd/stop`\n",
    "\n",
    "\n",
    "def render_agent(env_class, env_args: dict, net_dims: [int], agent_class, actor_path: str, render_times: int = 8):\n",
    "    env = build_env(env_class, env_args)\n",
    "\n",
    "    state_dim = env_args['state_dim']\n",
    "    action_dim = env_args['action_dim']\n",
    "    agent = agent_class(net_dims, state_dim, action_dim, gpu_id=-1)\n",
    "    actor = agent.act\n",
    "\n",
    "    print(f\"| render and load actor from: {actor_path}\")\n",
    "    actor.load_state_dict(torch.load(actor_path, map_location=lambda storage, loc: storage))\n",
    "    for i in range(render_times):\n",
    "        cumulative_reward, episode_step = get_rewards_and_steps(env, actor, if_render=True)\n",
    "        print(f\"|{i:4}  cumulative_reward {cumulative_reward:9.3f}  episode_step {episode_step:5.0f}\")\n",
    "\n",
    "        \n",
    "class Evaluator:\n",
    "    def __init__(self, eval_env, eval_per_step: int = 1e4, eval_times: int = 8, cwd: str = '.'):\n",
    "        self.cwd = cwd\n",
    "        self.env_eval = eval_env\n",
    "        self.eval_step = 0\n",
    "        self.total_step = 0\n",
    "        self.start_time = time.time()\n",
    "        self.eval_times = eval_times  # number of times that get episodic cumulative return\n",
    "        self.eval_per_step = eval_per_step  # evaluate the agent per training steps\n",
    "\n",
    "        self.recorder = []\n",
    "        print(f\"\\n| `step`: Number of samples, or total training steps, or running times of `env.step()`.\"\n",
    "              f\"\\n| `time`: Time spent from the start of training to this moment.\"\n",
    "              f\"\\n| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.\"\n",
    "              f\"\\n| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.\"\n",
    "              f\"\\n| `avgS`: Average of steps in an episode.\"\n",
    "              f\"\\n| `objC`: Objective of Critic network. Or call it loss function of critic network.\"\n",
    "              f\"\\n| `objA`: Objective of Actor network. It is the average Q value of the critic network.\"\n",
    "              f\"\\n| {'step':>8}  {'time':>8}  | {'avgR':>8}  {'stdR':>6}  {'avgS':>6}  | {'objC':>8}  {'objA':>8}\")\n",
    "            \n",
    "    def evaluate_and_save(self, actor, horizon_len: int, logging_tuple: tuple):\n",
    "        self.total_step += horizon_len\n",
    "        if self.eval_step + self.eval_per_step > self.total_step:\n",
    "            return\n",
    "        self.eval_step = self.total_step\n",
    "\n",
    "        rewards_steps_ary = [get_rewards_and_steps(self.env_eval, actor) for _ in range(self.eval_times)]\n",
    "        rewards_steps_ary = np.array(rewards_steps_ary, dtype=np.float32)\n",
    "        avg_r = rewards_steps_ary[:, 0].mean()  # average of cumulative rewards\n",
    "        std_r = rewards_steps_ary[:, 0].std()  # std of cumulative rewards\n",
    "        avg_s = rewards_steps_ary[:, 1].mean()  # average of steps in an episode\n",
    "\n",
    "        used_time = time.time() - self.start_time\n",
    "        self.recorder.append((self.total_step, used_time, avg_r))\n",
    "        \n",
    "        print(f\"| {self.total_step:8.2e}  {used_time:8.0f}  \"\n",
    "              f\"| {avg_r:8.2f}  {std_r:6.2f}  {avg_s:6.0f}  \"\n",
    "              f\"| {logging_tuple[0]:8.2f}  {logging_tuple[1]:8.2f}\")\n",
    "\n",
    "\n",
    "def get_rewards_and_steps(env, actor, if_render: bool = False) -> (float, int):  # cumulative_rewards and episode_steps\n",
    "    device = next(actor.parameters()).device  # net.parameters() is a Python generator.\n",
    "\n",
    "    state, _ = env.reset()\n",
    "    episode_steps = 0\n",
    "    cumulative_returns = 0.0  # sum of rewards in an episode\n",
    "    for episode_steps in range(12345):\n",
    "        tensor_state = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        tensor_action = actor(tensor_state)\n",
    "        action = tensor_action.detach().cpu().numpy()[0]  # not need detach(), because using torch.no_grad() outside\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        cumulative_returns += reward\n",
    "\n",
    "        if if_render:\n",
    "            env.render()\n",
    "        if done:\n",
    "            break\n",
    "    return cumulative_returns, episode_steps + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd1c23c7-51cc-45f6-8aa4-3036e5c0583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "# from elegantrl.agents import AgentA2C\n",
    "\n",
    "# from actor_ppo import (\n",
    "#     AgentPPO,\n",
    "#     Config,\n",
    "#     train_agent,\n",
    "# )\n",
    "\n",
    "MODELS = {\"ppo\": AgentPPO}\n",
    "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\n",
    "ON_POLICY_MODELS = [\"ppo\"]\n",
    "# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n",
    "#\n",
    "# NOISE = {\n",
    "#     \"normal\": NormalActionNoise,\n",
    "#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n",
    "# }\n",
    "\n",
    "\n",
    "class DRLAgent:\n",
    "    \"\"\"Implementations of DRL algorithms\n",
    "    Attributes\n",
    "    ----------\n",
    "        env: gym environment class\n",
    "            user-defined class\n",
    "    Methods\n",
    "    -------\n",
    "        get_model()\n",
    "            setup DRL algorithms\n",
    "        train_model()\n",
    "            train DRL algorithms in a train dataset\n",
    "            and output the trained model\n",
    "        DRL_prediction()\n",
    "            make a prediction in a test dataset and get results\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, price_array, tech_array, turbulence_array):\n",
    "        self.env = env\n",
    "        self.price_array = price_array\n",
    "        self.tech_array = tech_array\n",
    "        self.turbulence_array = turbulence_array\n",
    "\n",
    "    def get_model(self, model_name, model_kwargs):\n",
    "        env_config = {\n",
    "            \"price_array\": self.price_array,\n",
    "            \"tech_array\": self.tech_array,\n",
    "            \"turbulence_array\": self.turbulence_array,\n",
    "            \"if_train\": True,\n",
    "        }\n",
    "        environment = self.env(config=env_config)\n",
    "        env_args = {'config': env_config,\n",
    "              'env_name': environment.env_name,\n",
    "              'state_dim': environment.state_dim,\n",
    "              'action_dim': environment.action_dim,\n",
    "              'if_discrete': False}\n",
    "        agent = MODELS[model_name]\n",
    "        if model_name not in MODELS:\n",
    "            raise NotImplementedError(\"NotImplementedError\")\n",
    "        model = Config(agent_class=agent, env_class=self.env, env_args=env_args)\n",
    "        model.if_off_policy = model_name in OFF_POLICY_MODELS\n",
    "        if model_kwargs is not None:\n",
    "            try:\n",
    "                model.learning_rate = model_kwargs[\"learning_rate\"]\n",
    "                model.batch_size = model_kwargs[\"batch_size\"]\n",
    "                model.gamma = model_kwargs[\"gamma\"]\n",
    "                model.seed = model_kwargs[\"seed\"]\n",
    "                model.net_dims = model_kwargs[\"net_dimension\"]\n",
    "                model.target_step = model_kwargs[\"target_step\"]\n",
    "                model.eval_gap = model_kwargs[\"eval_gap\"]\n",
    "                model.eval_times = model_kwargs[\"eval_times\"]\n",
    "            except BaseException:\n",
    "                raise ValueError(\n",
    "                    \"Fail to read arguments, please check 'model_kwargs' input.\"\n",
    "                )\n",
    "        return model\n",
    "\n",
    "    def train_model(self, model, cwd, total_timesteps=5000):\n",
    "        model.cwd = cwd\n",
    "        model.break_step = total_timesteps\n",
    "        train_agent(model)\n",
    "\n",
    "    @staticmethod\n",
    "    def DRL_prediction(model_name, cwd, net_dimension, environment):\n",
    "        if model_name not in MODELS:\n",
    "            raise NotImplementedError(\"NotImplementedError\")\n",
    "        agent_class = MODELS[model_name]\n",
    "        environment.env_num = 1\n",
    "        agent = agent_class(net_dimension, environment.state_dim, environment.action_dim)\n",
    "        actor = agent.act\n",
    "        # load agent\n",
    "        try:\n",
    "            cwd = cwd + '/actor.pth'\n",
    "            print(f\"| load actor from: {cwd}\")\n",
    "            actor.load_state_dict(torch.load(cwd, map_location=lambda storage, loc: storage))\n",
    "            act = actor\n",
    "            device = agent.device\n",
    "        except BaseException:\n",
    "            raise ValueError(\"Fail to load agent!\")\n",
    "\n",
    "        # test on the testing env\n",
    "        _torch = torch\n",
    "        state, _ = environment.reset()\n",
    "        episode_returns = []  # the cumulative_return / initial_account\n",
    "        episode_total_assets = [environment.initial_total_asset]\n",
    "        with _torch.no_grad():\n",
    "            for i in range(environment.max_step):\n",
    "                s_tensor = _torch.as_tensor((state,), device=device)\n",
    "                a_tensor = act(s_tensor)  # action_tanh = act.forward()\n",
    "                action = (\n",
    "                    a_tensor.detach().cpu().numpy()[0]\n",
    "                )  # not need detach(), because with torch.no_grad() outside\n",
    "                state, reward, done, _, _ = environment.step(action)\n",
    "\n",
    "                total_asset = (\n",
    "                    environment.amount\n",
    "                    + (\n",
    "                        environment.price_ary[environment.day] * environment.stocks\n",
    "                    ).sum()\n",
    "                )\n",
    "                episode_total_assets.append(total_asset)\n",
    "                episode_return = total_asset / environment.initial_total_asset\n",
    "                episode_returns.append(episode_return)\n",
    "                if done:\n",
    "                    break\n",
    "        print(\"Test Finished!\")\n",
    "        # return episode total_assets on testing data\n",
    "        print(\"episode_return\", episode_return)\n",
    "        return episode_total_assets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edac7f64-9f11-4906-a945-f635aa44a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "# from elegantrl.agents import AgentA2C\n",
    "\n",
    "MODELS = {\"ppo\": AgentPPO}\n",
    "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\n",
    "ON_POLICY_MODELS = [\"ppo\"]\n",
    "# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n",
    "#\n",
    "# NOISE = {\n",
    "#     \"normal\": NormalActionNoise,\n",
    "#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n",
    "# }\n",
    "\n",
    "\n",
    "class DRLAgent:\n",
    "    \"\"\"Implementations of DRL algorithms\n",
    "    Attributes\n",
    "    ----------\n",
    "        env: gym environment class\n",
    "            user-defined class\n",
    "    Methods\n",
    "    -------\n",
    "        get_model()\n",
    "            setup DRL algorithms\n",
    "        train_model()\n",
    "            train DRL algorithms in a train dataset\n",
    "            and output the trained model\n",
    "        DRL_prediction()\n",
    "            make a prediction in a test dataset and get results\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, price_array, tech_array, turbulence_array):\n",
    "        self.env = env\n",
    "        self.price_array = price_array\n",
    "        self.tech_array = tech_array\n",
    "        self.turbulence_array = turbulence_array\n",
    "\n",
    "    def get_model(self, model_name, model_kwargs):\n",
    "        env_config = {\n",
    "            \"price_array\": self.price_array,\n",
    "            \"tech_array\": self.tech_array,\n",
    "            \"turbulence_array\": self.turbulence_array,\n",
    "            \"if_train\": True,\n",
    "        }\n",
    "        environment = self.env(config=env_config)\n",
    "        env_args = {'config': env_config,\n",
    "              'env_name': environment.env_name,\n",
    "              'state_dim': environment.state_dim,\n",
    "              'action_dim': environment.action_dim,\n",
    "              'if_discrete': False}\n",
    "        agent = MODELS[model_name]\n",
    "        if model_name not in MODELS:\n",
    "            raise NotImplementedError(\"NotImplementedError\")\n",
    "        model = Config(agent_class=agent, env_class=self.env, env_args=env_args)\n",
    "        model.if_off_policy = model_name in OFF_POLICY_MODELS\n",
    "        if model_kwargs is not None:\n",
    "            try:\n",
    "                model.learning_rate = model_kwargs[\"learning_rate\"]\n",
    "                model.batch_size = model_kwargs[\"batch_size\"]\n",
    "                model.gamma = model_kwargs[\"gamma\"]\n",
    "                model.seed = model_kwargs[\"seed\"]\n",
    "                model.net_dims = model_kwargs[\"net_dimension\"]\n",
    "                model.target_step = model_kwargs[\"target_step\"]\n",
    "                model.eval_gap = model_kwargs[\"eval_gap\"]\n",
    "                model.eval_times = model_kwargs[\"eval_times\"]\n",
    "            except BaseException:\n",
    "                raise ValueError(\n",
    "                    \"Fail to read arguments, please check 'model_kwargs' input.\"\n",
    "                )\n",
    "        return model\n",
    "\n",
    "    def train_model(self, model, cwd, total_timesteps=5000):\n",
    "        model.cwd = cwd\n",
    "        model.break_step = total_timesteps\n",
    "        train_agent(model)\n",
    "\n",
    "    @staticmethod\n",
    "    def DRL_prediction(model_name, cwd, net_dimension, environment):\n",
    "        if model_name not in MODELS:\n",
    "            raise NotImplementedError(\"NotImplementedError\")\n",
    "        agent_class = MODELS[model_name]\n",
    "        environment.env_num = 1\n",
    "        agent = agent_class(net_dimension, environment.state_dim, environment.action_dim)\n",
    "        actor = agent.act\n",
    "        # load agent\n",
    "        try:  \n",
    "            cwd = cwd + '/actor.pth'\n",
    "            print(f\"| load actor from: {cwd}\")\n",
    "            actor.load_state_dict(torch.load(cwd, map_location=lambda storage, loc: storage))\n",
    "            act = actor\n",
    "            device = agent.device\n",
    "        except BaseException:\n",
    "            raise ValueError(\"Fail to load agent!\")\n",
    "\n",
    "        # test on the testing env\n",
    "        _torch = torch\n",
    "        state, _ = environment.reset()\n",
    "        episode_returns = []  # the cumulative_return / initial_account\n",
    "        episode_total_assets = [environment.initial_total_asset]\n",
    "        with _torch.no_grad():\n",
    "            for i in range(environment.max_step):\n",
    "                s_tensor = _torch.as_tensor((state,), device=device)\n",
    "                a_tensor = act(s_tensor)  # action_tanh = act.forward()\n",
    "                action = (\n",
    "                    a_tensor.detach().cpu().numpy()[0]\n",
    "                )  # not need detach(), because with torch.no_grad() outside\n",
    "                state, reward, done, _, _ = environment.step(action)\n",
    "\n",
    "                total_asset = (\n",
    "                    environment.amount\n",
    "                    + (\n",
    "                        environment.price_ary[environment.day] * environment.stocks\n",
    "                    ).sum()\n",
    "                )\n",
    "                episode_total_assets.append(total_asset)\n",
    "                episode_return = total_asset / environment.initial_total_asset\n",
    "                episode_returns.append(episode_return)\n",
    "                if done:\n",
    "                    break\n",
    "        print(\"Test Finished!\")\n",
    "        # return episode total_assets on testing data\n",
    "        print(\"episode_return\", episode_return)\n",
    "        return episode_total_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27bbb409-b394-4a3f-84fe-29697403b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from finrl.config import ERL_PARAMS\n",
    "from finrl.config import INDICATORS\n",
    "from finrl.config import RLlib_PARAMS\n",
    "from finrl.config import SAC_PARAMS\n",
    "from finrl.config import TRAIN_END_DATE\n",
    "from finrl.config import TRAIN_START_DATE\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "\n",
    "# construct environment\n",
    "\n",
    "\n",
    "def train(\n",
    "    start_date,\n",
    "    end_date,\n",
    "    ticker_list,\n",
    "    data_source,\n",
    "    time_interval,\n",
    "    technical_indicator_list,\n",
    "    drl_lib,\n",
    "    env,\n",
    "    model_name,\n",
    "    if_vix=True,\n",
    "    **kwargs,\n",
    "):\n",
    "    # download data\n",
    "    dp = DataProcessor(data_source, **kwargs)\n",
    "    data = dp.download_data(ticker_list, start_date, end_date, time_interval)\n",
    "    data = dp.clean_data(data)\n",
    "    data = dp.add_technical_indicator(data, technical_indicator_list)\n",
    "    if if_vix:\n",
    "        data = dp.add_vix(data)\n",
    "    else:\n",
    "        data = dp.add_turbulence(data)\n",
    "    price_array, tech_array, turbulence_array = dp.df_to_array(data, if_vix)\n",
    "    env_config = {\n",
    "        \"price_array\": price_array,\n",
    "        \"tech_array\": tech_array,\n",
    "        \"turbulence_array\": turbulence_array,\n",
    "        \"if_train\": True,\n",
    "    }\n",
    "    env_instance = env(config=env_config)\n",
    "\n",
    "    # read parameters\n",
    "    cwd = kwargs.get(\"cwd\", \"./\" + str(model_name))\n",
    "\n",
    "    if drl_lib == \"elegantrl\":\n",
    "        DRLAgent_erl = DRLAgent\n",
    "        break_step = kwargs.get(\"break_step\", 1e6)\n",
    "        erl_params = kwargs.get(\"erl_params\")\n",
    "        agent = DRLAgent_erl(\n",
    "            env=env,\n",
    "            price_array=price_array,\n",
    "            tech_array=tech_array,\n",
    "            turbulence_array=turbulence_array,\n",
    "        )\n",
    "        model = agent.get_model(model_name, model_kwargs=erl_params)\n",
    "        trained_model = agent.train_model(\n",
    "            model=model, cwd=cwd, total_timesteps=break_step\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04722358-ab56-400b-8f59-ae0f906e913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from finrl.config import INDICATORS\n",
    "from finrl.config import RLlib_PARAMS\n",
    "from finrl.config import TEST_END_DATE\n",
    "from finrl.config import TEST_START_DATE\n",
    "\n",
    "def test(\n",
    "    start_date,\n",
    "    end_date,\n",
    "    ticker_list,\n",
    "    data_source,\n",
    "    time_interval,\n",
    "    technical_indicator_list,\n",
    "    drl_lib,\n",
    "    env,\n",
    "    model_name,\n",
    "    if_vix=True,\n",
    "    **kwargs,\n",
    "):\n",
    "\n",
    "    # import data processor\n",
    "    from finrl.meta.data_processor import DataProcessor\n",
    "\n",
    "    # fetch data\n",
    "    dp = DataProcessor(data_source, **kwargs)\n",
    "    data = dp.download_data(ticker_list, start_date, end_date, time_interval)\n",
    "    data = dp.clean_data(data)\n",
    "    data = dp.add_technical_indicator(data, technical_indicator_list)\n",
    "\n",
    "    if if_vix:\n",
    "        data = dp.add_vix(data)\n",
    "    else:\n",
    "        data = dp.add_turbulence(data)\n",
    "    price_array, tech_array, turbulence_array = dp.df_to_array(data, if_vix)\n",
    "\n",
    "    env_config = {\n",
    "        \"price_array\": price_array,\n",
    "        \"tech_array\": tech_array,\n",
    "        \"turbulence_array\": turbulence_array,\n",
    "        \"if_train\": False,\n",
    "    }\n",
    "    env_instance = env(config=env_config)\n",
    "\n",
    "    # load elegantrl needs state dim, action dim and net dim\n",
    "    net_dimension = kwargs.get(\"net_dimension\", 2**7)\n",
    "    cwd = kwargs.get(\"cwd\", \"./\" + str(model_name))\n",
    "    print(\"price_array: \", len(price_array))\n",
    "\n",
    "    if drl_lib == \"elegantrl\":\n",
    "        DRLAgent_erl = DRLAgent\n",
    "        episode_total_assets = DRLAgent_erl.DRL_prediction(\n",
    "            model_name=model_name,\n",
    "            cwd=cwd,\n",
    "            net_dimension=net_dimension,\n",
    "            environment=env_instance,\n",
    "        )\n",
    "        return episode_total_assets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
